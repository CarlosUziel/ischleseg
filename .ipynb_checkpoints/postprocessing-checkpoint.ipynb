{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports\n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.stats as st\n",
    "import nilearn\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from matplotlib.colors import colorConverter\n",
    "from glob import glob\n",
    "from scipy import ndimage\n",
    "from nilearn.image import resample_to_img, resample_img\n",
    "from nilearn.masking import compute_background_mask, compute_epi_mask\n",
    "from nilearn.plotting import plot_roi, plot_epi, plot_img, plot_anat\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from nipype.algorithms.metrics import Distance\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from scipy import interp\n",
    "from itertools import chain\n",
    "from scipy.ndimage.morphology import binary_dilation, binary_erosion, binary_closing, binary_opening\n",
    "from skimage.morphology import cube, octahedron, ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(original_path, predicted_path, mask_path, th=None):\n",
    "    original_data = nib.load(original_path).get_data()\n",
    "    predicted_data = nib.load(predicted_path).get_data()\n",
    "    mask_data = nib.load(mask_path).get_data() # use mask to limit results to the brain\n",
    "    \n",
    "    # Threshold data if necessary\n",
    "    if th is not None:\n",
    "        predicted_data = (predicted_data > th).astype(int)\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # Real positive cases\n",
    "    metrics['P'] = float(np.sum((original_data == 1).astype(int) * mask_data))\n",
    "\n",
    "    # Real negative cases\n",
    "    metrics['N'] = float(np.sum((original_data == 0).astype(int) * mask_data))\n",
    "\n",
    "    # True positive\n",
    "    metrics['TP'] = float(np.sum((((predicted_data == 1).astype(int) +\n",
    "                                   (original_data == 1).astype(int)) * mask_data) == 2))\n",
    "\n",
    "    # True negative\n",
    "    metrics['TN'] = float(np.sum((((predicted_data == 0).astype(int) +\n",
    "                                   (original_data == 0).astype(int)) * mask_data) == 2))\n",
    "\n",
    "    # False positive (all 1's in predicted minus original 1's)\n",
    "    metrics['FP'] = float(np.sum((((predicted_data == 1).astype(int) -\n",
    "                                   (original_data == 1).astype(int)) * mask_data) == 1))\n",
    "\n",
    "    # False negative\n",
    "    metrics['FN'] = float(np.sum((((predicted_data == 1).astype(int) -\n",
    "                                   (original_data == 1).astype(int)) * mask_data) == -1))\n",
    "\n",
    "    # True positive rate (Sensitivity, Recall)\n",
    "    metrics['TPR'] = metrics['TP'] / (metrics['TP'] + metrics['FN'])  \n",
    "\n",
    "    # True negative rate (Specificity)\n",
    "    metrics['TNR'] = metrics['TN'] / (metrics['TN'] + metrics['FP'])\n",
    "\n",
    "    # Positive predictive value (Precision)\n",
    "    metrics['PPV'] = metrics['TP'] / (metrics['TP'] + metrics['FP'])\n",
    "\n",
    "    # Negative predictive value\n",
    "    metrics['NPV'] = metrics['TN'] / (metrics['TN'] + metrics['FN'])\n",
    "\n",
    "    # False negative rate (Miss rate)\n",
    "    metrics['FNR'] = 1 -  metrics['TPR']\n",
    "\n",
    "    # False positive rate (Fall-out)\n",
    "    metrics['FPR'] = 1 - metrics['TNR']\n",
    "\n",
    "    # False discovery rate\n",
    "    metrics['FDR'] = 1 - metrics['PPV']\n",
    "\n",
    "    # False omission rate\n",
    "    metrics['FOR'] = 1 - metrics['NPV']\n",
    "\n",
    "    # Accuracy\n",
    "    metrics['ACC'] = (metrics['TP'] + metrics['TN']) / \\\n",
    "                                (metrics['TP'] + \n",
    "                                 metrics['TN'] + \n",
    "                                 metrics['FP'] + \n",
    "                                 metrics['FN'])\n",
    "\n",
    "    # F1 Score (also known as DSC, Sørensen–Dice coefficient, ...)\n",
    "    #metrics['F1S'] = 2 * (metrics['PPV'] * metrics['TPR']) / \\\n",
    "    #                                (metrics['PPV'] + metrics['TPR'])\n",
    "    metrics['F1S'] = (2*metrics['TP']) / (2*metrics['TP'] + metrics['FP'] + metrics['FN'])\n",
    "\n",
    "    # Matthews correlation coefficient\n",
    "    # The MCC can be more appropriate when negatives actually mean something,\n",
    "    # and can be more useful in other ways.\n",
    "    metrics['MCC'] = ((metrics['TP'] * metrics['TN']) - (metrics['FP'] * metrics['FN'])) / \\\n",
    "                        np.sqrt(\n",
    "                            (metrics['TP'] + metrics['FP']) *\n",
    "                            (metrics['TP'] + metrics['FN']) *\n",
    "                            (metrics['TN'] + metrics['FP']) *\n",
    "                            (metrics['TN'] + metrics['FN']))\n",
    "\n",
    "    # Compute Hausdorff distance\n",
    "    D = Distance()\n",
    "    if th is not None:\n",
    "        try:\n",
    "            metrics['HD'] = D._eucl_max(nib.load(original_path),\n",
    "                                        nib.Nifti1Image(predicted_data, nib.load(predicted_path).affine))\n",
    "        except:\n",
    "            metrics['HD'] = float('nan')\n",
    "    else:\n",
    "        metrics['HD'] = D._eucl_max(nib.load(original_path), nib.load(predicted_path))\n",
    "\n",
    "    # Compute Jaccard index\n",
    "    metrics['JI'] = metrics['TP'] / (metrics['FN'] + metrics['FP'] + metrics['TP'])\n",
    "\n",
    "    # Informedness or Bookmaker informedness\n",
    "    metrics['BM'] = metrics['TPR'] + metrics['TNR'] - 1\n",
    "\n",
    "    #Markedness\n",
    "    metrics['MK'] = metrics['PPV'] + metrics['NPV'] - 1\n",
    "\n",
    "    \n",
    "    return(metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir('/home/uziel/DISS')\n",
    "#os.chdir('/media/uziel/Pulga 2/DISS')\n",
    "# Set root of models to be post-processed\n",
    "root = \"/media/uziel/Pulga2/DISS/milestones_6\"\n",
    "model_variant = 'DM_V1_[0-4]' # choose model variant. Eg. \"DM_V0_[0-4]\".\n",
    "tmp = model_variant.split('_')\n",
    "if len(tmp) == 3:\n",
    "    model_name = tmp[1]\n",
    "elif len(tmp) == 4:\n",
    "    model_name = tmp[1] + '_' + tmp[2]\n",
    "else:\n",
    "    model_name = tmp[1] + '_' + tmp[2] + '_' + tmp[3]\n",
    "    \n",
    "# Load all trained models (k-folds) of model_variant\n",
    "trained_models = sorted(glob(os.path.join(root, model_variant)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POSTPROCESSING** for test cases\n",
    "\n",
    "Upsample predicted labels and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "##### POSTPROCESSING FOR K-FOLD CROSS-VALIDATION MODELS (0) ######\n",
    "##################################################################\n",
    "\n",
    "root_data = './data/ISLES2017/training'\n",
    "root_data_processed = './data_processed/ISLES2017/training'\n",
    "test_results = {}\n",
    "\n",
    "for model in trained_models:\n",
    "    root_1 = os.path.join(model, 'output/predictions/testSession/predictions')\n",
    "    root_2 = os.path.dirname(root_1)\n",
    "    \n",
    "    # Load label predictions\n",
    "    preds = sorted(glob(os.path.join(root_1, '*Segm.nii.gz')))\n",
    "    # Load probability maps of background\n",
    "    pmap_0 = sorted(glob(os.path.join(root_1, '*ProbMapClass0.nii.gz')))\n",
    "    # Load probability maps of foreground\n",
    "    pmap_1 = sorted(glob(os.path.join(root_1, '*ProbMapClass1.nii.gz')))\n",
    "    \n",
    "    test_results[os.path.basename(model)] = []\n",
    "    \n",
    "    # resize its prediction for final result validation\n",
    "    for i in range(len(preds)):\n",
    "        # Find subject that contains the code in pred.\n",
    "        subject = sorted([y\n",
    "                          for x in os.walk(root_data)\n",
    "                          for y in glob(os.path.join(x[0], '*'))\n",
    "                          if os.path.basename(preds[i]).split('_')[-2].split('.')[-1] in y\n",
    "                         ])[0].split('/')[-2]\n",
    "\n",
    "        subject_channels = sorted([y\n",
    "                                   for x in os.walk(os.path.join(root_data, subject))\n",
    "                                   for y in glob(os.path.join(x[0], '*MR_*.nii'))\n",
    "                                   if '4DPWI' not in y\n",
    "                                  ])\n",
    "        \n",
    "        subject_label = sorted([y\n",
    "                                for x in os.walk(os.path.join(root_data, subject))\n",
    "                                for y in glob(os.path.join(x[0], '*OT*.nii'))\n",
    "                               ])[0]\n",
    "\n",
    "        subject_processed = sorted([y\n",
    "                                    for x in os.walk(root_data_processed)\n",
    "                                    for y in glob(os.path.join(x[0], '*'))\n",
    "                                    if os.path.basename(preds[i]).split('_')[-2].split('.')[-1] in y\n",
    "                                   ])[0].split('/')[-2]\n",
    "        \n",
    "        subject_mask = sorted([y\n",
    "                               for x in os.walk(os.path.join(root_data_processed, subject_processed))\n",
    "                               for y in glob(os.path.join(x[0], '*mask*'))\n",
    "                              ])[0]\n",
    "        \n",
    "        # Load ADC channel as reference\n",
    "        original_img = nib.load(subject_channels[0])\n",
    "\n",
    "        # Load predictions and prob maps\n",
    "        pred_img = nib.load(preds[i])\n",
    "        pmap_0_img = nib.load(pmap_0[i])\n",
    "        pmap_1_img = nib.load(pmap_1[i])\n",
    "        \n",
    "        # Upsample to original size\n",
    "        pred_img = resample_img(pred_img,\n",
    "                                original_img.affine,\n",
    "                                original_img.shape,\n",
    "                                interpolation='nearest')\n",
    "        \n",
    "        pmap_0_img = resample_img(pmap_0_img,\n",
    "                                  original_img.affine,\n",
    "                                  original_img.shape,\n",
    "                                  interpolation='continuous')\n",
    "        \n",
    "        pmap_1_img = resample_img(pmap_1_img,\n",
    "                                  original_img.affine,\n",
    "                                  original_img.shape,\n",
    "                                  interpolation='continuous')\n",
    "        \n",
    "        # Load subject mask\n",
    "        mask_img = nib.load(subject_mask)\n",
    "        \n",
    "        # Upsample to original size\n",
    "        mask_img = resample_img(mask_img,\n",
    "                                original_img.affine,\n",
    "                                original_img.shape,\n",
    "                                interpolation='nearest')\n",
    "        \n",
    "        # Save prediction\n",
    "        pred_path = os.path.join(root_2, \"_\".join(os.path.basename(preds[i]).split('_')[:-1]) + '.pred.nii')\n",
    "        pmap_0_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_0[i]).split('_')[:-1]) + '.pmap_0.nii')\n",
    "        pmap_1_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_1[i]).split('_')[:-1]) + '.pmap_1.nii')\n",
    "        mask_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_1[i]).split('_')[:-1]) + '.mask.nii')\n",
    "        \n",
    "        nib.save(pred_img, pred_path)\n",
    "        nib.save(pmap_0_img, pmap_0_path)\n",
    "        nib.save(pmap_1_img, pmap_1_path)\n",
    "        nib.save(mask_img, mask_path)\n",
    "        \n",
    "        # Compute metrics between original and predicted label\n",
    "        metrics = get_metrics(subject_label, pred_path, mask_path)\n",
    "        \n",
    "        test_results[os.path.basename(model)].append([subject,\n",
    "                                                      subject_channels,\n",
    "                                                      subject_label,\n",
    "                                                      pred_path,\n",
    "                                                      pmap_0_path,\n",
    "                                                      pmap_1_path,\n",
    "                                                      mask_path,\n",
    "                                                      metrics])\n",
    "        \n",
    "    # Save model results\n",
    "    with open(os.path.join(model, 'test_results.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_results[os.path.basename(model)], output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    # Compute mean and std of model subjects predictions' metrics\n",
    "    metrics = np.array(test_results[os.path.basename(model)])[:,7]\n",
    "    test_metrics = {}\n",
    "    test_metrics['mean'] = {k : np.mean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    test_metrics['std'] = {k : np.std([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    \n",
    "    # Save each model's metrics\n",
    "    with open(os.path.join(model, 'test_metrics.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_metrics, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all models' results\n",
    "with open(os.path.join(root, model_name + '_test_results.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_results, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each model's metrics, compute mean and std. This is the final result of an experiment, and determines its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "test_metrics['mean'] = {k : np.mean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "test_metrics['std'] = {k : np.std([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics\n",
    "with open(os.path.join(root, model_name + '_test_metrics.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_metrics, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot original and predicted labels for test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC CURVE** for test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_fpr = {}\n",
    "model_mean_tpr = {}\n",
    "model_mean_auc = {}\n",
    "for model in trained_models:\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, _, _ in test_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    \n",
    "    model_mean_fpr[os.path.basename(model)] = fpr\n",
    "    model_mean_tpr[os.path.basename(model)] = tpr\n",
    "    model_mean_auc[os.path.basename(model)] = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "lw = 2\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for model in trained_models:\n",
    "    tprs.append(interp(mean_fpr, model_mean_fpr[os.path.basename(model)], model_mean_tpr[os.path.basename(model)]))\n",
    "    aucs.append(model_mean_auc[os.path.basename(model)])\n",
    "    plt.plot(model_mean_fpr[os.path.basename(model)], model_mean_tpr[os.path.basename(model)], lw=1, alpha=0.3,\n",
    "             label = 'Fold {0} (AUC = {1:0.2f})'\n",
    "             ''.format(os.path.basename(model).split('_')[-1], model_mean_auc[os.path.basename(model)]))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Luck', alpha=.8)\n",
    "plt.plot([0, 1], [1, 0], 'k:', lw=lw, label = 'EER')\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.xlabel('False Positive Rate', size=15)\n",
    "plt.ylabel('True Positive Rate', size=15)\n",
    "plt.title('Receiver operating characteristic curve (' + model_name + ')')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(root, model_name + '_test_roc.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRECISION-RECALL CURVE** for test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_precision = {}\n",
    "model_mean_recall = {}\n",
    "model_mean_ap = {}\n",
    "for model in trained_models:\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, _, _ in test_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    average_precision = average_precision_score(y_true, y_pred)\n",
    "    \n",
    "    model_mean_precision[os.path.basename(model)] = precision\n",
    "    model_mean_recall[os.path.basename(model)] = recall\n",
    "    model_mean_ap[os.path.basename(model)] = average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('F1S={0:0.1f}'.format(f_score), xy=(0.85, y[45] + 0.02))\n",
    "    \n",
    "lines.append(l)\n",
    "labels.append('iso-F1S curves')\n",
    "lw = 2\n",
    "for model in trained_models:\n",
    "    l, = plt.plot(model_mean_recall[os.path.basename(model)],\n",
    "                  model_mean_precision[os.path.basename(model)],\n",
    "                  lw=lw)\n",
    "    lines.append(l)\n",
    "    labels.append('Fold {0} (AP = {1:0.2f})'\n",
    "                  ''.format(os.path.basename(model).split('_')[-1],\n",
    "                            model_mean_ap[os.path.basename(model)]))\n",
    "\n",
    "#fig = plt.gcf()\n",
    "#fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('True Positive Rate (Recall)', size=15)\n",
    "plt.ylabel('Positive Predictive Value\\n(Precision)', size=15)\n",
    "plt.title('Precision-Recall curve (' + model_name + ')')\n",
    "plt.legend(lines, labels, loc='lower left')\n",
    "plt.savefig(os.path.join(root, model_name + '_test_pr.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POSTPROCESSING** for validation cases\n",
    "\n",
    "Upsample predicted labels and compute validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "##### POSTPROCESSING FOR K-FOLD CROSS-VALIDATION MODELS (0) ######\n",
    "##################################################################\n",
    "\n",
    "root_data = './data/ISLES2017/training'\n",
    "root_data_processed = './data_processed/ISLES2017/training'\n",
    "val_results = {}\n",
    "\n",
    "for model in trained_models:\n",
    "    root_1 = os.path.join(model, 'output/predictions/valSession/predictions')\n",
    "    root_2 = os.path.dirname(root_1)\n",
    "    \n",
    "    # Load label predictions\n",
    "    preds = sorted(glob(os.path.join(root_1, '*Segm.nii.gz')))\n",
    "    # Load probability maps of background\n",
    "    pmap_0 = sorted(glob(os.path.join(root_1, '*ProbMapClass0.nii.gz')))\n",
    "    # Load probability maps of foreground\n",
    "    pmap_1 = sorted(glob(os.path.join(root_1, '*ProbMapClass1.nii.gz')))\n",
    "    \n",
    "    val_results[os.path.basename(model)] = []\n",
    "    \n",
    "    # resize its prediction for final result validation\n",
    "    for i in range(len(preds)):\n",
    "        # Find subject that contains the code in pred.\n",
    "        subject = sorted([y\n",
    "                          for x in os.walk(root_data)\n",
    "                          for y in glob(os.path.join(x[0], '*'))\n",
    "                          if os.path.basename(preds[i]).split('_')[-2].split('.')[-1] in y\n",
    "                         ])[0].split('/')[-2]\n",
    "\n",
    "        subject_channels = sorted([y\n",
    "                                   for x in os.walk(os.path.join(root_data, subject))\n",
    "                                   for y in glob(os.path.join(x[0], '*MR_*.nii'))\n",
    "                                   if '4DPWI' not in y\n",
    "                                  ])\n",
    "        \n",
    "        subject_label = sorted([y\n",
    "                                for x in os.walk(os.path.join(root_data, subject))\n",
    "                                for y in glob(os.path.join(x[0], '*OT*.nii'))\n",
    "                               ])[0]\n",
    "\n",
    "        subject_processed = sorted([y\n",
    "                                    for x in os.walk(root_data_processed)\n",
    "                                    for y in glob(os.path.join(x[0], '*'))\n",
    "                                    if os.path.basename(preds[i]).split('_')[-2].split('.')[-1] in y\n",
    "                                   ])[0].split('/')[-2]\n",
    "        \n",
    "        subject_mask = sorted([y\n",
    "                               for x in os.walk(os.path.join(root_data_processed, subject_processed))\n",
    "                               for y in glob(os.path.join(x[0], '*mask*'))\n",
    "                              ])[0]\n",
    "        \n",
    "        # Load ADC channel as reference\n",
    "        original_img = nib.load(subject_channels[0])\n",
    "\n",
    "        # Load predictions and prob maps\n",
    "        pred_img = nib.load(preds[i])\n",
    "        pmap_0_img = nib.load(pmap_0[i])\n",
    "        pmap_1_img = nib.load(pmap_1[i])\n",
    "        \n",
    "        # Upsample to original size\n",
    "        pred_img = resample_img(pred_img,\n",
    "                                original_img.affine,\n",
    "                                original_img.shape,\n",
    "                                interpolation='nearest')\n",
    "        \n",
    "        pmap_0_img = resample_img(pmap_0_img,\n",
    "                                  original_img.affine,\n",
    "                                  original_img.shape,\n",
    "                                  interpolation='continuous')\n",
    "        \n",
    "        pmap_1_img = resample_img(pmap_1_img,\n",
    "                                  original_img.affine,\n",
    "                                  original_img.shape,\n",
    "                                  interpolation='continuous')\n",
    "        \n",
    "        # Load subject mask\n",
    "        mask_img = nib.load(subject_mask)\n",
    "        \n",
    "        # Upsample to original size\n",
    "        mask_img = resample_img(mask_img,\n",
    "                                original_img.affine,\n",
    "                                original_img.shape,\n",
    "                                interpolation='nearest')\n",
    "        \n",
    "        # Save prediction\n",
    "        pred_path = os.path.join(root_2, \"_\".join(os.path.basename(preds[i]).split('_')[:-1]) + '.pred.nii')\n",
    "        pmap_0_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_0[i]).split('_')[:-1]) + '.pmap_0.nii')\n",
    "        pmap_1_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_1[i]).split('_')[:-1]) + '.pmap_1.nii')\n",
    "        mask_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_1[i]).split('_')[:-1]) + '.mask.nii')\n",
    "        \n",
    "        nib.save(pred_img, pred_path)\n",
    "        nib.save(pmap_0_img, pmap_0_path)\n",
    "        nib.save(pmap_1_img, pmap_1_path)\n",
    "        nib.save(mask_img, mask_path)\n",
    "        \n",
    "        # Compute metrics between original and predicted label\n",
    "        metrics = get_metrics(subject_label, pred_path, mask_path)\n",
    "        \n",
    "        val_results[os.path.basename(model)].append([subject,\n",
    "                                                     subject_channels,\n",
    "                                                     subject_label,\n",
    "                                                     pred_path,\n",
    "                                                     pmap_0_path,\n",
    "                                                     pmap_1_path,\n",
    "                                                     mask_path,\n",
    "                                                     metrics])\n",
    "        \n",
    "    # Save model results\n",
    "    with open(os.path.join(model, 'val_results.pkl'), 'wb') as output:\n",
    "        pickle.dump(val_results[os.path.basename(model)], output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    # Compute mean and std of model subjects predictions' metrics\n",
    "    metrics = np.array(val_results[os.path.basename(model)])[:,7]\n",
    "    val_metrics = {}\n",
    "    val_metrics['mean'] = {k : np.mean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    val_metrics['std'] = {k : np.std([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    \n",
    "    # Save each model's metrics\n",
    "    with open(os.path.join(model, 'val_metrics.pkl'), 'wb') as output:\n",
    "        pickle.dump(val_metrics, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all models' results\n",
    "with open(os.path.join(root, model_name + '_val_results.pkl'), 'wb') as output:\n",
    "    pickle.dump(val_results, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each model's metrics, compute mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'val_metrics.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "val_metrics['mean'] = {k : np.mean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "val_metrics['std'] = {k : np.std([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics\n",
    "with open(os.path.join(root, model_name + '_val_metrics.pkl'), 'wb') as output:\n",
    "    pickle.dump(val_metrics, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot original and predicted labels for validation cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC CURVE** for validation cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_fpr = {}\n",
    "model_mean_tpr = {}\n",
    "model_mean_auc = {}\n",
    "for model in trained_models:\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, _, _ in val_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    \n",
    "    model_mean_fpr[os.path.basename(model)] = fpr\n",
    "    model_mean_tpr[os.path.basename(model)] = tpr\n",
    "    model_mean_auc[os.path.basename(model)] = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "lw = 2\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for model in trained_models:\n",
    "    tprs.append(interp(mean_fpr, model_mean_fpr[os.path.basename(model)], model_mean_tpr[os.path.basename(model)]))\n",
    "    aucs.append(model_mean_auc[os.path.basename(model)])\n",
    "    plt.plot(model_mean_fpr[os.path.basename(model)], model_mean_tpr[os.path.basename(model)], lw=1, alpha=0.3,\n",
    "             label = 'Fold {0} (AUC = {1:0.2f})'\n",
    "             ''.format(os.path.basename(model).split('_')[-1], model_mean_auc[os.path.basename(model)]))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Luck', alpha=.8)\n",
    "plt.plot([0, 1], [1, 0], 'k:', lw=lw, label = 'EER')\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.xlabel('False Positive Rate', size=15)\n",
    "plt.ylabel('True Positive Rate', size=15)\n",
    "plt.title('Receiver operating characteristic curve (' + model_name + ')')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(root, model_name + '_test_roc.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRECISION-RECALL CURVE** for validation cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_precision = {}\n",
    "model_mean_recall = {}\n",
    "model_mean_ap = {}\n",
    "for model in trained_models:\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, _, _ in val_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    average_precision = average_precision_score(y_true, y_pred)\n",
    "    \n",
    "    model_mean_precision[os.path.basename(model)] = precision\n",
    "    model_mean_recall[os.path.basename(model)] = recall\n",
    "    model_mean_ap[os.path.basename(model)] = average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('F1S={0:0.1f}'.format(f_score), xy=(0.85, y[45] + 0.02))\n",
    "    \n",
    "lines.append(l)\n",
    "labels.append('iso-F1S curves')\n",
    "lw = 2\n",
    "for model in trained_models:\n",
    "    l, = plt.plot(model_mean_recall[os.path.basename(model)],\n",
    "                  model_mean_precision[os.path.basename(model)],\n",
    "                  lw=lw)\n",
    "    lines.append(l)\n",
    "    labels.append('Fold {0} (AP = {1:0.2f})'\n",
    "                  ''.format(os.path.basename(model).split('_')[-1],\n",
    "                            model_mean_ap[os.path.basename(model)]))\n",
    "\n",
    "#fig = plt.gcf()\n",
    "#fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('True Positive Rate (Recall)', size=15)\n",
    "plt.ylabel('Positive Predictive Value\\n(Precision)', size=15)\n",
    "plt.title('Precision-Recall curve (' + model_name + ')')\n",
    "plt.legend(lines, labels, loc='lower left')\n",
    "plt.savefig(os.path.join(root, model_name + '_test_pr.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THRESHOLD TUNING V0**\n",
    "\n",
    "Use precision-recall curve on validation cases to maximize F1S on test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_metrics_tht_v0 = {}\n",
    "for model in trained_models:\n",
    "    # Compute best average threshold for validation cases\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, mask_path, _ in val_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    # Optimal threshold is where precision * recall is maximum\n",
    "    tmp = precision * recall        \n",
    "    # The closest point is the furthest from bottom-left corner\n",
    "    idx = np.argwhere(tmp == np.max(tmp))\n",
    "    th_op = thresholds[idx]\n",
    "    \n",
    "    all_test_metrics_tht_v0[os.path.basename(model)] = []\n",
    "    # Recompute test metrics with optimal threshold from validation cases\n",
    "    for _, _, subject_label, _, _, pmap_1_path, mask_path, _ in test_results[os.path.basename(model)]:\n",
    "        original_data = nib.load(subject_label).get_data()\n",
    "        predicted_data = nib.load(pmap_1_path).get_data()\n",
    "        \n",
    "        # Compute new metrics after new threshold\n",
    "        metrics = get_metrics(subject_label, pmap_1_path, mask_path, th_op)\n",
    "        metrics['TH_OP'] = th_op\n",
    "        all_test_metrics_tht_v0[os.path.basename(model)].append(metrics)\n",
    "        \n",
    "    metrics = np.array(all_test_metrics_tht_v0[os.path.basename(model)])\n",
    "    test_metrics_tht_v0 = {}\n",
    "    test_metrics_tht_v0['mean'] = {k : np.nanmean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    test_metrics_tht_v0['std'] = {k : np.nanstd([t[k] for t in metrics]) for k in metrics[0]}\n",
    "\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v0.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_metrics_tht_v0, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all metrics after threshold tuning v0 for future reference\n",
    "with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'wb') as output:\n",
    "    pickle.dump(all_test_metrics_tht_v0, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each model's metrics after **threshold tuning v0**, compute mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v0.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "test_metrics_tht_v0['mean'] = {k : np.nanmean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "test_metrics_tht_v0['std'] = {k : np.nanstd([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics after tht_v0\n",
    "with open(os.path.join(root, model_name + '_test_metrics_tht_v0.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_metrics_tht_v0, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THRESHOLD TUNING V1**\n",
    "\n",
    "Use ROC curve on validation cases to maximize BM on test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_metrics_tht_v1 = {}\n",
    "for model in trained_models:\n",
    "    # Compute best average threshold for validation cases\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, mask_path, _ in val_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    # Optimal threshold is where tpr - fpr is maximum\n",
    "    d = tpr - fpr\n",
    "    idx = np.argwhere(d == np.max(d))\n",
    "    th_op = thresholds[idx]\n",
    "    \n",
    "    all_test_metrics_tht_v1[os.path.basename(model)] = []\n",
    "    # Recompute test metrics with optimal threshold from validation cases\n",
    "    for _, _, subject_label, _, _, pmap_1_path, mask_path, _ in test_results[os.path.basename(model)]:\n",
    "        original_data = nib.load(subject_label).get_data()\n",
    "        predicted_data = nib.load(pmap_1_path).get_data()\n",
    "        \n",
    "        # Compute new metrics after new threshold\n",
    "        metrics = get_metrics(subject_label, pmap_1_path, mask_path, th_op)\n",
    "        metrics['TH_OP'] = th_op\n",
    "        all_test_metrics_tht_v1[os.path.basename(model)].append(metrics)\n",
    "        \n",
    "    metrics = np.array(all_test_metrics_tht_v1[os.path.basename(model)])\n",
    "    test_metrics_tht_v1 = {}\n",
    "    test_metrics_tht_v1['mean'] = {k : np.nanmean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    test_metrics_tht_v1['std'] = {k : np.nanstd([t[k] for t in metrics]) for k in metrics[0]}\n",
    "\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v1.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_metrics_tht_v1, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all metrics after threshold tuining for future reference\n",
    "with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'wb') as output:\n",
    "    pickle.dump(all_test_metrics_tht_v1, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each model's metrics after **threshold tuning v1**, compute mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v1.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "test_metrics_tht_v1['mean'] = {k : np.nanmean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "test_metrics_tht_v1['std'] = {k : np.nanstd([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics after tht_v1\n",
    "with open(os.path.join(root, model_name + '_test_metrics_tht_v1.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_metrics_tht_v1, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILL HOLES**\n",
    "\n",
    "Apply morphological operation of closing to fill holes in the predicted label (predicted segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define struct\n",
    "#struct = ndimage.generate_binary_structure(3, 3)\n",
    "struct = ball(3)\n",
    "all_test_metrics_de = {}\n",
    "for model in trained_models:\n",
    "    all_test_metrics_de[os.path.basename(model)] = []\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v0.pkl'), 'rb') as input:\n",
    "        metrics = pickle.load(input)\n",
    "        th = metrics['mean']['TH_OP']\n",
    "        \n",
    "    iterations = []\n",
    "    for _, _, subject_label, pred_label, _, pmap_1_path, mask_path, _ in val_results[os.path.basename(model)]:\n",
    "        original_data = nib.load(subject_label).get_data()\n",
    "        predicted_data = nib.load(pmap_1_path).get_data()\n",
    "        predicted_label = nib.load(pred_label).get_data()\n",
    "        \n",
    "        scores = []\n",
    "        for i in range(1,11):\n",
    "            try:\n",
    "                # Apply morphological operation of closing\n",
    "                #cl_data = binary_closing(predicted_data > th, struct, iterations=i)\n",
    "                cl_data = binary_closing(predicted_label, struct, iterations=i)\n",
    "                # Compute F1S\n",
    "                scores.append(f1_score(original_data.ravel(), cl_data.ravel()))\n",
    "            except:\n",
    "                break\n",
    "        # Get number of iterations that achieved max F1S\n",
    "        idx = np.argwhere(scores == np.max(scores))[0]\n",
    "        iterations.append(idx+1)        \n",
    "        \n",
    "    mean_iter = int(np.floor(np.mean(iterations)))\n",
    "    for _, _, subject_label, pred_label, _, pmap_1_path, mask_path, _ in test_results[os.path.basename(model)]:\n",
    "        original_data = nib.load(subject_label).get_data()\n",
    "        predicted_data = nib.load(pmap_1_path).get_data()\n",
    "        predicted_label = nib.load(pred_label).get_data()\n",
    "        \n",
    "        # Apply morphological operation of closing\n",
    "        #img = binary_closing(predicted_data > th, struct, iterations=mean_iter)\n",
    "        img = binary_closing(predicted_label, struct, iterations=mean_iter)\n",
    "        # Save image temporarly\n",
    "        temp_path = 'temp.nii.gz'\n",
    "        nib.save(nib.Nifti1Image(img.astype(int), nib.load(subject_label).affine), temp_path)\n",
    "        \n",
    "        # Recompute metrics\n",
    "        metrics = get_metrics(subject_label, temp_path, mask_path, 0)\n",
    "        metrics['TH_OP'] = 0\n",
    "        metrics['N_iter'] = mean_iter\n",
    "        all_test_metrics_de[os.path.basename(model)].append(metrics)\n",
    "        \n",
    "    metrics = np.array(all_test_metrics_de[os.path.basename(model)])\n",
    "    test_metrics_de = {}\n",
    "    test_metrics_de['mean'] = {k : np.nanmean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    test_metrics_de['std'] = {k : np.nanstd([t[k] for t in metrics]) for k in metrics[0]}\n",
    "\n",
    "    with open(os.path.join(model, 'test_metrics_de.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_metrics_de, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all metrics after dilation-erosion for future reference\n",
    "with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'wb') as output:\n",
    "    pickle.dump(all_test_metrics_de, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics_de.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "test_metrics_de['mean'] = {k : np.nanmean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "test_metrics_de['std'] = {k : np.nanstd([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics after tht_v1\n",
    "with open(os.path.join(root, model_name + '_test_metrics_de.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_metrics_de, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESS TRAINING AND VALIDATION RESULTS**\n",
    "\n",
    "Plot and save training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in trained_models:\n",
    "    # Plot and save training progress\n",
    "    os.system(\"python ischleseg/deepmedic/plotSaveTrainingProgress.py \" +\n",
    "              os.path.join(model, \"output/logs/trainSession.txt -d -m 20 -s\"))\n",
    "    # Move files to the corresponding model directory\n",
    "    os.system(\"mv trainingProgress.pdf \" + os.path.join(model, 'trainingProgress_' + os.path.basename(model) + '.pdf'))\n",
    "    os.system(\"mv trainingProgress.pkl \" + os.path.join(model, 'trainingProgress.pkl'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training metrics and compute mean and variance between models (includes training and validation metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"measuredMetricsFromAllExperiments\"\n",
    "# 1st dimension: \"Validation\" (0), \"Training\" (1)\n",
    "# 2nd dimension: ? (0)\n",
    "# 3rd dimension: \"Mean Accuracy\" (0), \"Sensitivity\" (1), \"Specificity\" (2), \"DSC (samples)\" (3), \"DSC (full-segm)\" (4)\n",
    "\n",
    "metrics = {}\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'trainingProgress.pkl'), 'rb') as input:\n",
    "        metrics[os.path.basename(model)] = np.array(pickle.load(input))\n",
    "        metrics[os.path.basename(model)][0,0,4] = np.array(metrics[os.path.basename(model)][0,0,4])\n",
    "        \n",
    "# Compute mean and variance of all models' variations metrics\n",
    "metrics_mean = {}\n",
    "metrics_std = {}\n",
    "metrics_values = np.array(metrics.values())\n",
    "metrics_names_0 = ['Validation', 'Training']\n",
    "metrics_names_1 = ['Mean Accuracy', 'Sensitivity', 'Specificity', 'DSC (Samples)', 'DSC (full-segm)']\n",
    "\n",
    "for i in range(len(metrics_names_0)):\n",
    "    metrics_mean[metrics_names_0[i]] = {}\n",
    "    metrics_std[metrics_names_0[i]] = {}\n",
    "    for j in range(len(metrics_names_1)):\n",
    "        if i == 1 and j == 4: # Skip DSC_full for training (is never calculated)\n",
    "            metrics_mean[metrics_names_0[i]][metrics_names_1[j]] = np.zeros(35*20)\n",
    "            metrics_std[metrics_names_0[i]][metrics_names_1[j]] = np.zeros(35*20)\n",
    "            continue \n",
    "        metrics_mean[metrics_names_0[i]][metrics_names_1[j]] = np.mean(metrics_values[:,i,0,j])\n",
    "        metrics_std[metrics_names_0[i]][metrics_names_1[j]] = np.std(metrics_values[:,i,0,j])\n",
    "\n",
    "train_val_metrics = {}\n",
    "train_val_metrics['mean'] = metrics_mean\n",
    "train_val_metrics['std'] = metrics_std\n",
    "# Save final experiment progress metrics\n",
    "with open(os.path.join(root, model_name + '_train_val_metrics.pkl'), 'wb') as output:\n",
    "    pickle.dump(train_val_metrics, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot mean training and validation progress metrics of all trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "plt.close('all')\n",
    "rows, cols = [5, 2]\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*6, rows*3))\n",
    "\n",
    "for ax, col in zip(axes[0], metrics_names_0):\n",
    "    ax.set_title(col, pad=20, size=15)\n",
    "\n",
    "for ax, row in zip(axes[:,0], metrics_names_1):\n",
    "    ax.set_ylabel(row, rotation='vertical', size=15)\n",
    "    ax.yaxis.set_label_coords(-0.15, 0.5)\n",
    "    \n",
    "    \n",
    "for i in range(len(metrics_names_0)):\n",
    "    for j in range(len(metrics_names_1)):       \n",
    "        upper = np.minimum(metrics_mean[metrics_names_0[i]][metrics_names_1[j]] +\n",
    "                           metrics_std[metrics_names_0[i]][metrics_names_1[j]], 1)\n",
    "        lower = np.maximum(metrics_mean[metrics_names_0[i]][metrics_names_1[j]] -\n",
    "                           metrics_std[metrics_names_0[i]][metrics_names_1[j]], 0)\n",
    "        if i == 0 and j == 4:\n",
    "            x = np.arange(0, 40, 5)\n",
    "        else:\n",
    "            x = np.arange(0, 35, 1/20.0)\n",
    "        \n",
    "        axes[j,i].plot(x, metrics_mean[metrics_names_0[i]][metrics_names_1[j]], 'r')        \n",
    "        axes[j,i].fill_between(x, lower, upper,\n",
    "                         color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "        axes[j,i].set_xlim(0, 35)\n",
    "        axes[j,i].set_ylim(0, 1.0)\n",
    "        if j == 4:\n",
    "            axes[j,i].set_xlabel('Epoch', size=13)\n",
    "        \n",
    "        if j == 4 and i == 0:\n",
    "            axes[j,i].legend(loc=(0.9, -0.5))\n",
    "        axes[j,i].yaxis.grid(True)\n",
    "\n",
    "# Save mean training and validation metrics of all trained models averaged\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "plt.savefig(os.path.join(root, model_name + '_meanTrainValProgress.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ERROR BARS** for test cases\n",
    "\n",
    "Plot [0,1] metrics error bars in a 4x3 figure. Each row represents the results of each detection step (0=network output, 1=threshold tuning v0, 2=threshold tuning v1, 3=fill holes). Each column represents the error bars for the three groups of strokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Load all test cases from all folds (43)\n",
    "error_bars_metrics = {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                      '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                      '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                      '3':{'1':[], '2':[], '3':[], '4':[]}}\n",
    "# Define keys that will be part of the error bars\n",
    "keys = ['F1S', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        \n",
    "        subject, _, _, _, _, _, _, metrics_0 = all_test_metrics[os.path.basename(model)][i]\n",
    "        stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "        # Store only the metrics that go from 0 to 1\n",
    "        # 4 is the 'ALL' category\n",
    "        error_bars_metrics['0'][stroke_type].append([metrics_0[key] for key in keys])\n",
    "        error_bars_metrics['0']['4'].append([metrics_0[key] for key in keys])\n",
    "\n",
    "        metrics_1 = all_test_metrics_tht_v0[os.path.basename(model)][i]\n",
    "        error_bars_metrics['1'][stroke_type].append([metrics_1[key] for key in keys])\n",
    "        error_bars_metrics['1']['4'].append([metrics_1[key] for key in keys])\n",
    "        \n",
    "        metrics_2 = all_test_metrics_tht_v1[os.path.basename(model)][i]\n",
    "        error_bars_metrics['2'][stroke_type].append([metrics_2[key] for key in keys])\n",
    "        error_bars_metrics['2']['4'].append([metrics_2[key] for key in keys])\n",
    "        \n",
    "        metrics_3 = all_test_metrics_de[os.path.basename(model)][i]\n",
    "        error_bars_metrics['3'][stroke_type].append([metrics_3[key] for key in keys])\n",
    "        error_bars_metrics['3']['4'].append([metrics_3[key] for key in keys])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = ['Base', 'THT0', 'THT1', 'FH']\n",
    "col_labels = ['Lacunar/Subcortical', 'Small cortical', 'Big cortical/Main artery', 'All']\n",
    "\n",
    "x_labels = ['DSC', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "plt.close('all')\n",
    "rows, cols = [4, 4]\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(3*cols, rows*2))\n",
    "\n",
    "for ax, col in zip(axes[0], col_labels):\n",
    "    ax.set_title(col, pad=20, size=15)\n",
    "\n",
    "for ax, row in zip(axes[:,0], row_labels):\n",
    "    ax.set_ylabel(row, rotation='vertical', size=15)\n",
    "    ax.yaxis.set_label_coords(-0.3, 0.5)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(1,cols+1):\n",
    "        # Compute mean and confidence interval\n",
    "        metrics = error_bars_metrics[str(i)][str(j)]\n",
    "        mean = np.mean(metrics, axis=0)\n",
    "        confidence_interval = st.t.interval(0.95, len(metrics[0])-1,\n",
    "                                            loc=mean, scale=st.sem(metrics, axis=0))\n",
    "        differences = (abs(confidence_interval[0] - mean), abs(confidence_interval[1] - mean))\n",
    "        \n",
    "        # Plot error bar\n",
    "        axes[i,j-1].grid()\n",
    "        axes[i,j-1].set_ylim([0,1])\n",
    "        axes[i,j-1].tick_params(axis='x', width=10)\n",
    "        (_, caps, _) = axes[i,j-1].errorbar(x_labels, mean, differences,\n",
    "                                    color='red', mew=5,\n",
    "                                    fmt='o', markersize=3, capsize=10)\n",
    "\n",
    "        for cap in caps:\n",
    "            cap.set_markeredgewidth(1)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "plt.savefig(os.path.join(root, model_name + '_test_error_bars.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISUAL SEGMENTATION COMPARISON**\n",
    "\n",
    "Plot the predicted segmentations for each phase. Rows are subjects, columns phases. Plot three times with the best 5 results of each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Set best cut in z coordinate for each subject\n",
    "tr_cut_coords = {'training_1': [11], 'training_2': [16], 'training_4': [13], 'training_5': [11], 'training_6': [16],\n",
    "                 'training_7': [15], 'training_8': [15], 'training_9': [14], 'training_10': [12], 'training_11': [9],\n",
    "                 'training_12': [12], 'training_13': [15], 'training_14': [15], 'training_15': [16], 'training_16': [16],\n",
    "                 'training_18': [9], 'training_19': [15], 'training_20': [15], 'training_21': [10], 'training_22': [13],\n",
    "                 'training_23': [15], 'training_24': [12], 'training_26': [14], 'training_27': [11], 'training_28': [21],\n",
    "                 'training_30': [14], 'training_31': [19], 'training_32': [14], 'training_33': [18], 'training_35': [17],\n",
    "                 'training_36': [16], 'training_37': [15], 'training_38': [15], 'training_39': [10], 'training_40': [11],\n",
    "                 'training_41': [11], 'training_42': [12], 'training_43': [8], 'training_44': [14], 'training_45': [9],\n",
    "                 'training_46': [12], 'training_47': [15], 'training_48': [12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all test cases from all folds (43)\n",
    "base_metrics = {'1':[], '2':[], '3':[]}\n",
    "subjects_info = {'1':[], '2':[], '3':[]}\n",
    "\n",
    "# Define keys\n",
    "keys = ['F1S']\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        subject, subject_channels, subject_label, pred_path, _, pmap_1_path, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "        stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "        subjects_info[stroke_type].append([subject, subject_channels, subject_label, pred_path, pmap_1_path])\n",
    "        \n",
    "        f1s_0 = metrics['F1S']\n",
    "        f1s_1 = all_test_metrics_tht_v0[os.path.basename(model)][i]['F1S']\n",
    "        f1s_2 = all_test_metrics_tht_v1[os.path.basename(model)][i]['F1S']\n",
    "        f1s_3 = all_test_metrics_de[os.path.basename(model)][i]['F1S']\n",
    "        th_op_0 = all_test_metrics_tht_v0[os.path.basename(model)][i]['TH_OP']\n",
    "        th_op_1 = all_test_metrics_tht_v1[os.path.basename(model)][i]['TH_OP']\n",
    "        n_iter = all_test_metrics_de[os.path.basename(model)][i]['N_iter']\n",
    "        \n",
    "        base_metrics[stroke_type].append([f1s_0, f1s_1, f1s_2, f1s_3,\n",
    "                                          th_op_0, th_op_1, n_iter])\n",
    "        \n",
    "# Create all three plots\n",
    "col_labels = ['ADC', 'Ground truth', 'Base', 'THT0', 'THT1', 'FH']\n",
    "\n",
    "# generate the colors for your colormap\n",
    "color1 = colorConverter.to_rgba('white')\n",
    "\n",
    "# make the colormaps\n",
    "cmap1 = mpl.colors.LinearSegmentedColormap.from_list('my_cmap',['black','red'],256)\n",
    "\n",
    "cmap1._init() # create the _lut array, with rgba values\n",
    "\n",
    "# create your alpha array and fill the colormap with them.\n",
    "# here it is progressive, but you can create whathever you want\n",
    "alphas = np.linspace(0, 0.8, cmap1.N+3)\n",
    "cmap1._lut[:,-1] = alphas\n",
    "\n",
    "# Number of subjects to show\n",
    "n = 3\n",
    "for i in range(1,4):\n",
    "    plt.close('all')\n",
    "    rows, cols = [n,6]\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(15, n*2))\n",
    "    \n",
    "    # Get the 5 subjects with the highest F1S\n",
    "    f1s_list = [x[0] for x in base_metrics[str(i)]]\n",
    "    indexes = np.lexsort((range(len(subjects_info[str(i)])), f1s_list))[::-1]\n",
    "    all_subjects = [subjects_info[str(i)][idx] for idx in indexes][:n]    \n",
    "    row_labels = [x[0] for x in all_subjects]\n",
    "    base_metrics[str(i)] = [base_metrics[str(i)][idx] for idx in indexes][:n]\n",
    "    \n",
    "    for ax, col in zip(axes[0], col_labels):\n",
    "        ax.set_title(col, color='w', pad=30)\n",
    "\n",
    "    for ax, row in zip(axes[:,0], row_labels):\n",
    "        ax.set_ylabel(row.split('_')[-1], rotation=0, size='large', color='white')\n",
    "        ax.yaxis.set_label_coords(-0.5, 0.5)\n",
    "    \n",
    "    \n",
    "    for j in range(len(all_subjects)):\n",
    "        # Cut coords for this subject\n",
    "        cut_coords = tr_cut_coords[all_subjects[j][0]][0]\n",
    "        channel_ADC = all_subjects[j][1][0]\n",
    "        ADC_data = nib.load(channel_ADC).get_data()\n",
    "        \n",
    "        # Find best bounding box\n",
    "        data_2d = ADC_data[:,:,cut_coords]\n",
    "        idx = np.nonzero(data_2d)\n",
    "        # row_min, row_max, col_min, col_max\n",
    "        bbox = [np.min(idx[0]), np.max(idx[0]), np.min(idx[1]), np.max(idx[1])] \n",
    "        \n",
    "        # 0 - ADC Channel\n",
    "        axes[j,0].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,0].set_xlabel('z=%d' % cut_coords, color='w')\n",
    "        axes[j,0].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 1 - Ground truth\n",
    "        label_data = nib.load(all_subjects[j][2]).get_data()\n",
    "        vol = np.sum(label_data) * 0.001\n",
    "        axes[j,1].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,1].imshow(label_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.7, interpolation='none')\n",
    "        axes[j,1].set_xlabel('DSC: 1\\n%.2f cm3' % vol, color='w')\n",
    "        axes[j,1].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 2 - Base prediction\n",
    "        prediction_data = nib.load(all_subjects[j][3]).get_data()\n",
    "        vol = np.sum(prediction_data) * 0.001\n",
    "        axes[j,2].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,2].imshow(prediction_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.5, interpolation='none')\n",
    "        axes[j,2].set_xlabel('DSC: %.2f\\n%.2f cm3' % (base_metrics[str(i)][j][0], vol), color='w')\n",
    "        axes[j,2].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 3 - THT V0\n",
    "        thtv0_data = (nib.load(all_subjects[j][4]).get_data() > base_metrics[str(i)][j][4]).astype(int)\n",
    "        vol = np.sum(thtv0_data) * 0.001\n",
    "        axes[j,3].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,3].imshow(thtv0_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.5, interpolation='none')\n",
    "        axes[j,3].set_xlabel('DSC: %.2f\\n%.2f cm3' % (base_metrics[str(i)][j][1], vol), color='w')\n",
    "        axes[j,3].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 4 - THT V1\n",
    "        thtv1_data = (nib.load(all_subjects[j][4]).get_data() > base_metrics[str(i)][j][5]).astype(int)\n",
    "        vol = np.sum(thtv1_data) * 0.001\n",
    "        axes[j,4].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,4].imshow(thtv0_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.5, interpolation='none')\n",
    "        axes[j,4].set_xlabel('DSC: %.2f\\n%.2f cm3' % (base_metrics[str(i)][j][2], vol), color='w')\n",
    "        axes[j,4].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 5 - Fill holes\n",
    "        struct = ball(3)\n",
    "        fh_data = binary_closing(nib.load(all_subjects[j][3]).get_data(),\n",
    "                                 struct, iterations=base_metrics[str(i)][j][6]).astype(int)\n",
    "        vol = np.sum(fh_data) * 0.001\n",
    "        axes[j,5].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,5].imshow(fh_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.5, interpolation='none')\n",
    "        axes[j,5].set_xlabel('DSC: %.2f\\n%.2f cm3' % (base_metrics[str(i)][j][3], vol), color='w')\n",
    "        axes[j,5].xaxis.set_label_coords(0.5, -0.1)\n",
    "\n",
    "    \n",
    "        fig.subplots_adjust(hspace=0.5, wspace=-0.7)\n",
    "\n",
    "    \n",
    "    # save figure\n",
    "    fig.patch.set_facecolor('xkcd:black')\n",
    "    fig.savefig(os.path.join(root, model_name + '_test_seg_comparison_group_%d.pdf' % i),\n",
    "                bbox_inches='tight', facecolor=fig.get_facecolor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BLAND-ALTMAN PLOT**\n",
    "\n",
    "The Bland-Altman plot (Bland & Altman, 1986 and 1999), or difference plot, is a graphical method to compare two measurements techniques. In this graphical method the differences (or alternatively the ratios) between the two techniques are plotted against the averages of the two techniques. Alternatively (Krouwer, 2008) the differences can be plotted against one of the two methods, if this method is a reference or \"gold standard\" method.\n",
    "\n",
    "Horizontal lines are drawn at the mean difference, and at the limits of agreement, which are defined as the mean difference plus and minus 1.96 times the standard deviation of the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Load all test cases from all folds (43)\n",
    "bland_altman_metrics = {'0':{'1':[], '2':[], '3':[]},\n",
    "                        '1':{'1':[], '2':[], '3':[]},\n",
    "                        '2':{'1':[], '2':[], '3':[]},\n",
    "                        '3':{'1':[], '2':[], '3':[]},\n",
    "                        '4':{'1':[], '2':[], '3':[]}}\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        \n",
    "        subject, _, subject_label, pred_path, _, pmap_1_path, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "        stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "        \n",
    "        # 0 - Original\n",
    "        f1s = 1\n",
    "        vol = np.sum(nib.load(subject_label).get_data())\n",
    "        bland_altman_metrics['0'][stroke_type].append([f1s, vol])\n",
    "        \n",
    "        # 1 - Base\n",
    "        f1s = metrics['F1S']\n",
    "        vol = np.sum(nib.load(pred_path).get_data())\n",
    "        bland_altman_metrics['1'][stroke_type].append([f1s, vol])\n",
    "        \n",
    "        # 2 - THT v0\n",
    "        f1s = all_test_metrics_tht_v0[os.path.basename(model)][i]['F1S']\n",
    "        th = all_test_metrics_tht_v0[os.path.basename(model)][i]['TH_OP']\n",
    "        vol = np.sum(nib.load(pmap_1_path).get_data() > th)\n",
    "        bland_altman_metrics['2'][stroke_type].append([f1s, vol])\n",
    "        \n",
    "        # 3 - THT v1\n",
    "        f1s = all_test_metrics_tht_v1[os.path.basename(model)][i]['F1S']\n",
    "        th = all_test_metrics_tht_v1[os.path.basename(model)][i]['TH_OP']\n",
    "        vol = np.sum(nib.load(pmap_1_path).get_data() > th)\n",
    "        bland_altman_metrics['3'][stroke_type].append([f1s, vol])\n",
    "        \n",
    "        # 4 - Fill holes\n",
    "        f1s = all_test_metrics_de[os.path.basename(model)][i]['F1S']\n",
    "        N_iter = all_test_metrics_de[os.path.basename(model)][i]['N_iter']\n",
    "        struct = ball(3)\n",
    "        vol = np.sum(binary_closing(nib.load(pred_path).get_data(), struct, iterations=N_iter))\n",
    "        bland_altman_metrics['4'][stroke_type].append([f1s, vol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = ['Base', 'THT0', 'THT1', 'FH']\n",
    "col_labels = ['Lacunar/Subcortical', 'Small cortical', 'Big cortical/Main artery']\n",
    "graphs = ['DSC', 'VOL']\n",
    "\n",
    "for i in range(len(graphs)):\n",
    "    plt.close('all')\n",
    "    rows, cols = [4, 3]\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 12))\n",
    "\n",
    "    for ax, col in zip(axes[0], col_labels):\n",
    "        ax.set_title(col, pad=30, size=15)\n",
    "\n",
    "    for ax, row in zip(axes[:,0], row_labels):\n",
    "        ax.set_ylabel(row, rotation='vertical', size=15)\n",
    "        ax.yaxis.set_label_coords(-0.2, 0.5)\n",
    "\n",
    "\n",
    "    for j in range(1,rows+1):\n",
    "        for k in range(1,cols+1):\n",
    "            # Get reference metric\n",
    "            ref = np.array([x[i] for x in bland_altman_metrics['0'][str(k)]])\n",
    "            # Get subjects metric\n",
    "            metrics = np.array([x[i] for x in bland_altman_metrics[str(j)][str(k)]])\n",
    "            # COnver mm3 to cm3\n",
    "            if i == 1:\n",
    "                ref, metrics = [ref*0.001, metrics*0.001]\n",
    "            # Compute difference (Y) and average (X)\n",
    "            diff, avg = [ref - metrics, np.mean(np.array([ref, metrics]), axis=0)]\n",
    "            # Compute mean and std of differences\n",
    "            diff_mean, diff_std = [np.mean(diff), np.std(diff)]\n",
    "            # Plot difference against average\n",
    "            axes[j-1,k-1].plot(avg, diff, 'ro')\n",
    "            # Plot mean difference line and std lines\n",
    "            axes[j-1,k-1].axhline(diff_mean, color='k', label='Mean difference (%.2f)' % diff_mean)\n",
    "            axes[j-1,k-1].axhline(diff_mean + 1.9*diff_std, linestyle='--', color='k',\n",
    "                                  label='Mean' + r'$\\pm1.96$' + ' STD')\n",
    "            axes[j-1,k-1].axhline(diff_mean - 1.9*diff_std, linestyle='--', color='k')\n",
    "            \n",
    "            if i == 0:                \n",
    "                axes[j-1,k-1].set_xlim([0.5,1])\n",
    "                axes[j-1,k-1].set_ylim([0,1])\n",
    "            \n",
    "            if k == cols:\n",
    "                axes[j-1,k-1].set_ylabel('Difference (GT - Pred)\\n%s' % ('DSC (F1S)' if i == 0 else 'Volume (cm3)'), size=12)\n",
    "                axes[j-1,k-1].yaxis.set_label_coords(1.2, 0.5)\n",
    "            \n",
    "            if j == rows:\n",
    "                axes[j-1,k-1].set_xlabel('Average (Pred, GT)\\n%s' % ('DSC (F1S)' if i == 0 else 'Volume (cm3)'), size=12)\n",
    "            \n",
    "            axes[j-1,k-1].legend(loc='lower left')\n",
    "            \n",
    "            axes[j-1,k-1].grid()\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "    #plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    plt.savefig(os.path.join(root, model_name + '_bland_altman_%s.pdf' % graphs[i]), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METRICS SUMMARY TABLE**\n",
    "\n",
    "Table with as many rows as metrics. Columns: Base, THT V0, % Improvement, THT V1, % Improvement, Fill Holes, % Improvement. Use pandas for the table (dataframe) so that it can be exported to latex: pd.to_latex()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Load all test cases from all folds (43)\n",
    "summary_table_metrics = {'0':{'1':[], '2':[], '3':[]},\n",
    "                         '1':{'1':[], '2':[], '3':[]},\n",
    "                         '2':{'1':[], '2':[], '3':[]},\n",
    "                         '3':{'1':[], '2':[], '3':[]}}\n",
    "\n",
    "# Define keys\n",
    "keys = np.array(['F1S', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV'])\n",
    "x_labels = ['DSC', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        \n",
    "        subject, _, _, _, _, _, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "        stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "        # Store only the metrics that go from 0 to 1\n",
    "        summary_table_metrics['0'][stroke_type].append([metrics[key] for key in keys])        \n",
    "\n",
    "        metrics = all_test_metrics_tht_v0[os.path.basename(model)][i]\n",
    "        summary_table_metrics['1'][stroke_type].append([metrics[key] for key in keys])        \n",
    "        \n",
    "        metrics = all_test_metrics_tht_v1[os.path.basename(model)][i]\n",
    "        summary_table_metrics['2'][stroke_type].append([metrics[key] for key in keys])\n",
    "        \n",
    "        metrics = all_test_metrics_de[os.path.basename(model)][i]\n",
    "        summary_table_metrics['3'][stroke_type].append([metrics[key] for key in keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALl metrics\n",
    "data_base = np.array([np.nanmean(summary_table_metrics['0']['1'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['0']['1'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['0']['2'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['0']['2'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['0']['3'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['0']['3'], axis=0)])\n",
    "\n",
    "all_0 = np.array([np.nanmean(np.vstack((summary_table_metrics['0']['1'],\n",
    "                                     summary_table_metrics['0']['2'],\n",
    "                                     summary_table_metrics['0']['3'])), axis=0),\n",
    "                  np.nanstd(np.vstack((summary_table_metrics['0']['1'],\n",
    "                                    summary_table_metrics['0']['2'],\n",
    "                                    summary_table_metrics['0']['3'])), axis=0)])\n",
    "\n",
    "data_tht_v0 = np.array([np.nanmean(summary_table_metrics['1']['1'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['1']['1'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['1']['2'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['1']['2'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['1']['3'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['1']['3'], axis=0)])\n",
    "\n",
    "all_1 = np.array([np.nanmean(np.vstack((summary_table_metrics['1']['1'],\n",
    "                                     summary_table_metrics['1']['2'],\n",
    "                                     summary_table_metrics['1']['3'])), axis=0),\n",
    "                  np.nanstd(np.vstack((summary_table_metrics['1']['1'],\n",
    "                                    summary_table_metrics['1']['2'],\n",
    "                                    summary_table_metrics['1']['3'])), axis=0)])\n",
    "\n",
    "data_tht_v1 = np.array([np.nanmean(summary_table_metrics['2']['1'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['2']['1'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['2']['2'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['2']['2'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['2']['3'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['2']['3'], axis=0)])\n",
    "\n",
    "all_2 = np.array([np.nanmean(np.vstack((summary_table_metrics['2']['1'],\n",
    "                                     summary_table_metrics['2']['2'],\n",
    "                                     summary_table_metrics['2']['3'])), axis=0),\n",
    "                  np.nanstd(np.vstack((summary_table_metrics['2']['1'],\n",
    "                                    summary_table_metrics['2']['2'],\n",
    "                                    summary_table_metrics['2']['3'])), axis=0)])\n",
    "\n",
    "data_de = np.array([np.nanmean(summary_table_metrics['3']['1'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['3']['1'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['3']['2'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['3']['2'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['3']['3'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['3']['3'], axis=0)])\n",
    "\n",
    "all_3 = np.array([np.nanmean(np.vstack((summary_table_metrics['3']['1'],\n",
    "                                     summary_table_metrics['3']['2'],\n",
    "                                     summary_table_metrics['3']['3'])), axis=0),\n",
    "                  np.nanstd(np.vstack((summary_table_metrics['3']['1'],\n",
    "                                    summary_table_metrics['3']['2'],\n",
    "                                    summary_table_metrics['3']['3'])), axis=0)])\n",
    "\n",
    "data = np.concatenate((data_base, all_0,\n",
    "                       data_tht_v0, all_1,\n",
    "                       data_tht_v1, all_2,\n",
    "                       data_de, all_3)).T\n",
    "\n",
    "header = [np.array(['Base']*8 + ['THT0']*8 + \\\n",
    "                   ['THT1']*8 + ['FH']*8),\n",
    "          np.array(['L', 'L', 'S', 'S', 'B', 'B', 'ALL', 'ALL']*4),\n",
    "          np.array(['AVG', 'STD']*16)]\n",
    "\n",
    "df = pd.DataFrame(data, index=x_labels, columns=header)\n",
    "df = df.round(2)\n",
    "\n",
    "# Save dataframe in latex format\n",
    "out = open(os.path.join(root, model_name + '_metrics_table_0'), \"w\")\n",
    "print >> out, df.T.to_latex(column_format='|c|c|c|ccccccc|',\n",
    "                            longtable=True, bold_rows=True, multicolumn_format='c',\n",
    "                            multirow=True)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvement metrics\n",
    "data_improv_0 = np.vstack(((data_tht_v0[[0,2,4]] - data_base[[0,2,4]]) / data_base[[0,2,4]] * 100,\n",
    "                          (all_1[0] - all_0[0]) / all_0[0] * 100))\n",
    "data_improv_1 = np.vstack(((data_tht_v1[[0,2,4]] - data_base[[0,2,4]]) / data_base[[0,2,4]] * 100,\n",
    "                           (all_2[0] - all_0[0]) / all_0[0] * 100))\n",
    "data_improv_2 = np.vstack(((data_de[[0,2,4]] - data_base[[0,2,4]]) / data_base[[0,2,4]] * 100,\n",
    "                           (all_3[0] - all_0[0]) / all_0[0] * 100))\n",
    "\n",
    "data_improv = np.concatenate((data_improv_0,\n",
    "                              data_improv_1,\n",
    "                              data_improv_2))\n",
    "\n",
    "header = [np.array(['THT0']*4 + \\\n",
    "                   ['THT1']*4 + ['FH']*4),\n",
    "          np.array(['L', 'S', 'B', 'ALL']*3)]\n",
    "df = pd.DataFrame(data_improv.T, index=x_labels, columns=header)\n",
    "df = df.round(2)\n",
    "\n",
    "# Save dataframe in latex format\n",
    "out = open(os.path.join(root, model_name + '_metrics_table_1'), \"w\")\n",
    "print >> out, df.T.to_latex(column_format='|c|c|ccccccc|',\n",
    "                            longtable=True, bold_rows=True, multicolumn_format='c',\n",
    "                            multirow=True)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CORRELATION BETWEEN METRICS AND VOLUME**\n",
    "\n",
    "Coefficient of Correlation\n",
    "\n",
    "Value of r\tStrength of relationship\n",
    "\n",
    "-1.0 to -0.5 or 1.0 to 0.5\tStrong\n",
    "\n",
    "-0.5 to -0.3 or 0.3 to 0.5\tModerate\n",
    "\n",
    "-0.3 to -0.1 or 0.1 to 0.3\tWeak\n",
    "\n",
    "-0.1 to 0.1\tNone or very weak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all test cases from all folds (43)\n",
    "corr_metrics = {'0': [], '1': [], '2': [], '3': []}\n",
    "corr_volumes = []\n",
    "\n",
    "keys = np.array(['F1S', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV'])\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        \n",
    "        subject, _, subject_label, pred_path, _, pmap_1_path, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "        \n",
    "        # 0 - Original label\n",
    "        corr_volumes.append(np.sum(nib.load(subject_label).get_data()))\n",
    "        \n",
    "        # 1 - Base\n",
    "        #vol = np.sum(nib.load(pred_path).get_data())\n",
    "        corr_metrics['0'].append([metrics[key] for key in keys])\n",
    "        \n",
    "        # 2 - THT v0\n",
    "        metrics = all_test_metrics_tht_v0[os.path.basename(model)][i]\n",
    "        th = all_test_metrics_tht_v0[os.path.basename(model)][i]['TH_OP']\n",
    "        #vol = np.sum(nib.load(pmap_1_path).get_data() > th)\n",
    "        corr_metrics['1'].append([metrics[key] for key in keys])\n",
    "        \n",
    "        # 3 - THT v1\n",
    "        metrics = all_test_metrics_tht_v1[os.path.basename(model)][i]\n",
    "        th = all_test_metrics_tht_v1[os.path.basename(model)][i]['TH_OP']\n",
    "        #vol = np.sum(nib.load(pmap_1_path).get_data() > th)\n",
    "        corr_metrics['2'].append([metrics[key] for key in keys])\n",
    "        \n",
    "        # 4 - Fill holes\n",
    "        metrics = all_test_metrics_de[os.path.basename(model)][i]\n",
    "        N_iter = all_test_metrics_de[os.path.basename(model)][i]['N_iter']\n",
    "        struct = ball(3)\n",
    "        #vol = np.sum(binary_closing(nib.load(pred_path).get_data(), struct, iterations=N_iter))\n",
    "        corr_metrics['3'].append([metrics[key] for key in keys])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each stage (base, tht v0,...) and each metric, compute correlation with volume\n",
    "col_labels = ['Base', 'THT0', 'THT1', 'FH']\n",
    "row_labels = ['DSC', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "plt.close('all')\n",
    "rows, cols = [len(row_labels), len(col_labels)]\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(4*cols, 2*rows))\n",
    "\n",
    "for ax, col in zip(axes[0], col_labels):\n",
    "    ax.set_title(col, pad=25, size=15)\n",
    "\n",
    "for ax, row in zip(axes[:,0], row_labels):\n",
    "    ax.set_ylabel(row, rotation='horizontal', size=15)\n",
    "    ax.yaxis.set_label_coords(-0.3, 0.5)\n",
    "    \n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        metric = np.array([x[i] for x in corr_metrics[str(j)]])\n",
    "        volumes = np.array(corr_volumes)*0.001\n",
    "        corr, p = pearsonr(metric, volumes)\n",
    "        \n",
    "        idx = np.lexsort((metric, volumes))\n",
    "        \n",
    "        axes[i,j].scatter(volumes[idx], metric[idx], c='r')\n",
    "                \n",
    "        axes[i,j].set_xlim([0,25])    \n",
    "        \n",
    "        if i != 1:\n",
    "            axes[i,j].set_ylim([0,1])\n",
    "        else:\n",
    "            axes[i,j].set_ylim([0,150])\n",
    "        \n",
    "        if i == rows-1:\n",
    "            axes[i,j].set_xlabel('r=%0.2f, p=%0.5f' % (corr, p) + '\\n\\nGT volume (cm3)', size = 15)\n",
    "        else:\n",
    "            axes[i,j].set_xlabel('r=%0.2f, p=%0.5f' % (corr, p), size = 15)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.2)\n",
    "fig.savefig(os.path.join(root, model_name + '_corr_figure.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V0 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V0_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V0_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V0_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V0_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V0_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V0_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V0_de = pickle.load(input)\n",
    "\n",
    "# V1 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V1_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V1_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V1_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V1_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V1_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V1_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V1_de = pickle.load(input)\n",
    "\n",
    "# V2 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V2_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V2 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V2_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V2_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V2_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V2_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V2_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V2_de = pickle.load(input)\n",
    "    \n",
    "# V3 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V3_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V3 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V3_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V3_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V3_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V3_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V3_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V3_de = pickle.load(input)\n",
    "    \n",
    "# V4 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V4_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V4 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V4_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V4_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V4_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V4_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V4_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V4_de = pickle.load(input)\n",
    "    \n",
    "# V5 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V5_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V5 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V5_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V5_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V5_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V5_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V5_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V5_de = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V0_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V0_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V0_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V0_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V0_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V0_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V0_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V0_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V0_R_de = pickle.load(input)\n",
    "    \n",
    "# V1_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V1_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V1_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V1_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V1_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V1_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V1_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V1_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V1_R_de = pickle.load(input)\n",
    "    \n",
    "# V2_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V2_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V2_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V2_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V2_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V2_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V2_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V2_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V2_R_de = pickle.load(input)\n",
    "    \n",
    "# V3_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V3_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V3_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V3_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V3_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V3_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V3_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V3_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V3_R_de = pickle.load(input)\n",
    "    \n",
    "# V4_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V4_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V4_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V4_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V4_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V4_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V4_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V4_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V4_R_de = pickle.load(input)\n",
    "    \n",
    "# V5_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V5_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V5_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V5_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V5_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V5_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V5_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V5_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V5_R_de = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUMMARY OF ALL EXPERIMENTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variants = ['DM_V0_[0-4]', 'DM_V1_[0-4]', 'DM_V2_[0-4]', 'DM_V3_[0-4]']\n",
    "\n",
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Load all test cases from all folds (43)\n",
    "summary_table_metrics = {'V0':\n",
    "                         {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '3':{'1':[], '2':[], '3':[], '4':[]}},\n",
    "                         'V1':\n",
    "                         {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '3':{'1':[], '2':[], '3':[], '4':[]}},\n",
    "                         'V2':\n",
    "                         {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '3':{'1':[], '2':[], '3':[], '4':[]}},\n",
    "                         'V3':\n",
    "                         {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '3':{'1':[], '2':[], '3':[], '4':[]}}}\n",
    "\n",
    "# Define keys\n",
    "keys = np.array(['F1S', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV'])\n",
    "x_labels = ['DSC', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "# Get all metrics from all experiments\n",
    "for model_variant in model_variants:\n",
    "    tmp = model_variant.split('_')\n",
    "    if len(tmp) == 3:\n",
    "        model_name = tmp[1]\n",
    "    elif len(tmp) == 4:\n",
    "        model_name = tmp[1] + '_' + tmp[2]\n",
    "    else:\n",
    "        model_name = tmp[1] + '_' + tmp[2] + '_' + tmp[3]\n",
    "\n",
    "    # Load all trained models (k-folds) of model_variant\n",
    "    trained_models = sorted(glob(os.path.join(root, model_variant)))\n",
    "\n",
    "    for model in trained_models:\n",
    "        # Load metrics from network\n",
    "        with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "            all_test_metrics = pickle.load(input)\n",
    "        # Load metrics from tht_v0\n",
    "        with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "            all_test_metrics_tht_v0 = pickle.load(input)\n",
    "        # Load metrics from tht_v1\n",
    "        with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "            all_test_metrics_tht_v1 = pickle.load(input)\n",
    "        # Load metrics from de\n",
    "        with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "            all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "        for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "\n",
    "            subject, _, _, _, _, _, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "            stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "            # Store only the metrics that go from 0 to 1\n",
    "            summary_table_metrics[model_name]['0'][stroke_type].append([metrics[key] for key in keys])\n",
    "            summary_table_metrics[model_name]['0']['4'].append([metrics[key] for key in keys])\n",
    "\n",
    "            metrics = all_test_metrics_tht_v0[os.path.basename(model)][i]\n",
    "            summary_table_metrics[model_name]['1'][stroke_type].append([metrics[key] for key in keys])\n",
    "            summary_table_metrics[model_name]['1']['4'].append([metrics[key] for key in keys])\n",
    "\n",
    "            metrics = all_test_metrics_tht_v1[os.path.basename(model)][i]\n",
    "            summary_table_metrics[model_name]['2'][stroke_type].append([metrics[key] for key in keys])\n",
    "            summary_table_metrics[model_name]['2']['4'].append([metrics[key] for key in keys])\n",
    "\n",
    "            metrics = all_test_metrics_de[os.path.basename(model)][i]\n",
    "            summary_table_metrics[model_name]['3'][stroke_type].append([metrics[key] for key in keys])\n",
    "            summary_table_metrics[model_name]['3']['4'].append([metrics[key] for key in keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUMMARY TABLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0_metrics = np.array([np.nanmean(np.vstack((summary_table_metrics['V0']['0']['1'],\n",
    "                                             summary_table_metrics['V0']['0']['2'],\n",
    "                                             summary_table_metrics['V0']['0']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V0']['3']['1'],\n",
    "                                             summary_table_metrics['V0']['3']['2'],\n",
    "                                             summary_table_metrics['V0']['3']['3'])),\n",
    "                                  axis=0)\n",
    "                      ])\n",
    "\n",
    "v1_metrics = np.array([np.nanmean(np.vstack((summary_table_metrics['V1']['0']['1'],\n",
    "                                             summary_table_metrics['V1']['0']['2'],\n",
    "                                             summary_table_metrics['V1']['0']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V1']['3']['1'],\n",
    "                                             summary_table_metrics['V1']['3']['2'],\n",
    "                                             summary_table_metrics['V1']['3']['3'])),\n",
    "                                  axis=0)\n",
    "                      ])\n",
    "\n",
    "v2_metrics = np.array([np.nanmean(np.vstack((summary_table_metrics['V2']['0']['1'],\n",
    "                                             summary_table_metrics['V2']['0']['2'],\n",
    "                                             summary_table_metrics['V2']['0']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V2']['3']['1'],\n",
    "                                             summary_table_metrics['V2']['3']['2'],\n",
    "                                             summary_table_metrics['V2']['3']['3'])),\n",
    "                                  axis=0)\n",
    "                      ])\n",
    "\n",
    "v3_metrics = np.array([np.nanmean(np.vstack((summary_table_metrics['V3']['0']['1'],\n",
    "                                             summary_table_metrics['V3']['0']['2'],\n",
    "                                             summary_table_metrics['V3']['0']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V3']['3']['1'],\n",
    "                                             summary_table_metrics['V3']['3']['2'],\n",
    "                                             summary_table_metrics['V3']['3']['3'])),\n",
    "                                  axis=0)\n",
    "                      ])\n",
    "\n",
    "data = np.concatenate((v0_metrics,\n",
    "                       v1_metrics,\n",
    "                       v2_metrics,\n",
    "                       v3_metrics)).T\n",
    "\n",
    "header =[np.array(['V0']*2 + ['V1']*2 + ['V2']*2 + ['V3']*2),\n",
    "         np.array(['Base', 'FH']*4)]\n",
    "\n",
    "df = pd.DataFrame(data, index=x_labels, columns=header)\n",
    "df = df.round(2)\n",
    "\n",
    "# Save dataframe in latex format\n",
    "out = open(os.path.join(root, 'summary_table'), \"w\")\n",
    "print >> out, df.T.to_latex(column_format='|c|c|c|cccccc|',\n",
    "                            longtable=True, bold_rows=True, multicolumn_format='c',\n",
    "                            multirow=True)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUMMARY ERROR BARS FIGURE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_labels = ['Base', 'THT0', 'THT1', 'FH']\n",
    "col_labels = ['Lacunar/\\nSubcortical', 'Small cortical', 'Big cortical/\\nMain artery', 'All']\n",
    "\n",
    "x_labels = ['V0', 'V1', 'V2', 'V3']\n",
    "\n",
    "plt.close('all')\n",
    "rows, cols = [4, 4]\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(2*cols, 2*rows))\n",
    "\n",
    "for ax, col in zip(axes[0], col_labels):\n",
    "    ax.set_title(col, pad=20, size=12)\n",
    "\n",
    "for ax, row in zip(axes[:,0], row_labels):\n",
    "    ax.set_ylabel(row, rotation='vertical', size=12)\n",
    "    ax.yaxis.set_label_coords(-0.5, 0.5)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(1,cols+1):\n",
    "        # Compute mean and confidence interval\n",
    "        metrics = np.array([[x[0] for x in summary_table_metrics['V0'][str(i)][str(j)]],\n",
    "                            [x[0] for x in summary_table_metrics['V1'][str(i)][str(j)]],\n",
    "                            [x[0] for x in summary_table_metrics['V2'][str(i)][str(j)]],\n",
    "                            [x[0] for x in summary_table_metrics['V3'][str(i)][str(j)]]]).T\n",
    "        \n",
    "        mean = np.mean(metrics, axis=0)\n",
    "        confidence_interval = st.t.interval(0.95, len(metrics[0])-1,\n",
    "                                            loc=mean, scale=st.sem(metrics, axis=0))\n",
    "        differences = (abs(confidence_interval[0] - mean), abs(confidence_interval[1] - mean))\n",
    "        \n",
    "        # Plot error bar\n",
    "        axes[i,j-1].grid()\n",
    "        axes[i,j-1].set_ylim([0,1])\n",
    "        axes[i,j-1].tick_params(axis='x', width=10)\n",
    "        (_, caps, _) = axes[i,j-1].errorbar(x_labels, mean, differences,\n",
    "                                    color='red', mew=5,\n",
    "                                    fmt='o', markersize=3, capsize=6)\n",
    "\n",
    "        for cap in caps:\n",
    "            cap.set_markeredgewidth(1)\n",
    "            \n",
    "        if j == cols:\n",
    "            axes[i,j-1].set_ylabel('DSC', size=12)\n",
    "            axes[i,j-1].yaxis.set_label_coords(1.3, 0.5)\n",
    "\n",
    "        if i == rows-1:\n",
    "            axes[i,j-1].set_xlabel('Experiments', size=12)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.5)\n",
    "plt.savefig(os.path.join(root, 'summary_error_bars.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
