{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports\n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy import ndimage\n",
    "from nilearn.image import resample_to_img, resample_img\n",
    "from nilearn.masking import compute_background_mask, compute_epi_mask\n",
    "from nilearn.plotting import plot_roi, plot_epi\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from nipype.algorithms.metrics import Distance\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from scipy import interp\n",
    "from itertools import chain\n",
    "from scipy.ndimage.morphology import binary_dilation, binary_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir('/home/uziel/DISS')\n",
    "# Set root of models to be post-processed\n",
    "root = \"./milestones_4\"\n",
    "model_variant = 'DM_V0_[0-4]' # choose model variant. Eg. \"DM_V0_[0-4]\".\n",
    "tmp = model_variant.split('_')\n",
    "if len(tmp) == 3:\n",
    "    model_name = tmp[1]\n",
    "elif len(tmp) == 4:\n",
    "    model_name = tmp[1] + '_' + tmp[2]\n",
    "else:\n",
    "    model_name = tmp[1] + '_' + tmp[2] + '_' + tmp[3]\n",
    "trained_models = sorted(glob(os.path.join(root, model_variant)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET ERROR MAPS**\n",
    "\n",
    "Compute error maps for the best performing model. Get probability maps for class 0 and 1 for all validation subjects across all folds (should sum up to 43). Obtain error maps by substracting each subject's probability map from the ground truth. Save error maps. For each trained model, create files listing error maps corresponding to the training subjects (and validation?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder in data for error maps\n",
    "error_map_path = './data_processed/error_maps'\n",
    "if not os.path.exists(error_map_path): os.mkdir(error_map_path)\n",
    "# Get all probability maps for class 0 and 1 from model variant X (43)\n",
    "prob_maps_class_0 = []\n",
    "prob_maps_class_1 = []\n",
    "for model in trained_models:\n",
    "    root_1 = os.path.join(model, 'output/predictions/trainSession/predictions')\n",
    "\n",
    "    # Load probability maps of background\n",
    "    prob_maps_class_0 += (glob(os.path.join(root_1, '*ProbMapClass0.nii.gz')))\n",
    "    # Load probability maps of foreground\n",
    "    prob_maps_class_1 += (glob(os.path.join(root_1, '*ProbMapClass1.nii.gz')))\n",
    "\n",
    "prob_maps_class_0 = sorted(prob_maps_class_0)\n",
    "prob_maps_class_1 = sorted(prob_maps_class_1)\n",
    "\n",
    "# Get all ground truth labels for all training subjects (43)\n",
    "root_2 = './data_processed/ISLES2017/training'\n",
    "subject_labels = sorted([y\n",
    "                         for x in os.walk(root_2)\n",
    "                         for y in glob(os.path.join(x[0], '*OT*.nii.gz'))\n",
    "                         if 'clone' not in y\n",
    "                        ])\n",
    "\n",
    "# Subject code in prediction files comes from MTT channel\n",
    "subject_mtt = sorted([y\n",
    "                      for x in os.walk(root_2)\n",
    "                      for y in glob(os.path.join(x[0], '*MTT*.nii.gz'))\n",
    "                      if 'clone' not in y\n",
    "                     ])\n",
    "\n",
    "# Compute error maps\n",
    "for i in range(len(subject_mtt)):\n",
    "    # Load label\n",
    "    label = nib.load(subject_labels[i])\n",
    "    \n",
    "    # Get subject code\n",
    "    code = os.path.basename(subject_mtt[i]).split('.')[-3]\n",
    "    \n",
    "    # Get probability maps of subject code\n",
    "    pmap_0 = [m for m in prob_maps_class_0 if code in m][0]\n",
    "    pmap_1 = [m for m in prob_maps_class_1 if code in m][0]\n",
    "    \n",
    "    pmap_0_img = nib.load(pmap_0)\n",
    "    pmap_1_img = nib.load(pmap_1)\n",
    "    \n",
    "    # Compute square error map\n",
    "    emap_0 = ((label.get_data() == 0).astype(int) - pmap_0_img.get_data())**2\n",
    "    emap_1 = (label.get_data() - pmap_1_img.get_data())**2\n",
    "    \n",
    "    # Normalize\n",
    "    emap_0 = (emap_0 - np.mean(emap_0))/np.std(emap_0)\n",
    "    emap_1 = (emap_1 - np.mean(emap_1))/np.std(emap_1)\n",
    "    \n",
    "    # Save error maps\n",
    "    nib.save(nib.Nifti1Image(emap_0, pmap_0.affine),\n",
    "             os.path.join(error_map_path, 'EMAP.' + code + '.nii.gz'))\n",
    "    nib.save(nib.Nifti1Image(emap_1, pmap_1.affine),\n",
    "             os.path.join(error_map_path, 'EMAP.' + code + '.nii.gz'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATE CONFIGURATION FILES FOR WEIGHTED MAPS**\n",
    "\n",
    "weightedMapsForSamplingEachCategoryTrain = [\"./weightMapsForeground.cfg\", \"./weightMapsBackground.cfg\"]\n",
    "#weightedMapsForSamplingEachCategoryVal = [\"./validation/weightMapsForeground.cfg\", \"./validation/weightMapsBackground.cfg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best performing model variant\n",
    "model_variant = 'DM_V0_[0-4]'\n",
    "model_variant = 'DM_V2_[0-4]' # choose model variant. Eg. \"DM_V0_[0-4]\".\n",
    "tmp = model_variant.split('_')\n",
    "if len(tmp) == 3:\n",
    "    model_name = tmp[1]\n",
    "elif len(tmp) == 4:\n",
    "    model_name = tmp[1] + '_' + tmp[2]\n",
    "else:\n",
    "    model_name = tmp[1] + '_' + tmp[2] + '_' + tmp[3]\n",
    "\n",
    "# Load all trained models (k-folds) of model_variant\n",
    "trained_models = sorted(glob(os.path.join(root, model_variant)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
