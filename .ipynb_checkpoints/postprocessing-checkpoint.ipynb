{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports\n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.stats as st\n",
    "import nilearn\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from matplotlib.colors import colorConverter\n",
    "from glob import glob\n",
    "from scipy import ndimage\n",
    "from nilearn.image import resample_to_img, resample_img\n",
    "from nilearn.masking import compute_background_mask, compute_epi_mask\n",
    "from nilearn.plotting import plot_roi, plot_epi, plot_img, plot_anat\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from nipype.algorithms.metrics import Distance\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from scipy import interp\n",
    "from itertools import chain\n",
    "from scipy.ndimage.morphology import binary_dilation, binary_erosion, binary_closing, binary_opening\n",
    "from skimage.morphology import cube, octahedron, ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(original_path, predicted_path, mask_path, th=None):\n",
    "    original_data = nib.load(original_path).get_data()\n",
    "    predicted_data = nib.load(predicted_path).get_data()\n",
    "    mask_data = nib.load(mask_path).get_data() # use mask to limit results to the brain\n",
    "    \n",
    "    # Threshold data if necessary\n",
    "    if th is not None:\n",
    "        predicted_data = (predicted_data > th).astype(int)\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # Real positive cases\n",
    "    metrics['P'] = float(np.sum((original_data == 1).astype(int) * mask_data))\n",
    "\n",
    "    # Real negative cases\n",
    "    metrics['N'] = float(np.sum((original_data == 0).astype(int) * mask_data))\n",
    "\n",
    "    # True positive\n",
    "    metrics['TP'] = float(np.sum((((predicted_data == 1).astype(int) +\n",
    "                                   (original_data == 1).astype(int)) * mask_data) == 2))\n",
    "\n",
    "    # True negative\n",
    "    metrics['TN'] = float(np.sum((((predicted_data == 0).astype(int) +\n",
    "                                   (original_data == 0).astype(int)) * mask_data) == 2))\n",
    "\n",
    "    # False positive (all 1's in predicted minus original 1's)\n",
    "    metrics['FP'] = float(np.sum((((predicted_data == 1).astype(int) -\n",
    "                                   (original_data == 1).astype(int)) * mask_data) == 1))\n",
    "\n",
    "    # False negative\n",
    "    metrics['FN'] = float(np.sum((((predicted_data == 1).astype(int) -\n",
    "                                   (original_data == 1).astype(int)) * mask_data) == -1))\n",
    "\n",
    "    # True positive rate (Sensitivity, Recall)\n",
    "    metrics['TPR'] = metrics['TP'] / (metrics['TP'] + metrics['FN'])  \n",
    "\n",
    "    # True negative rate (Specificity)\n",
    "    metrics['TNR'] = metrics['TN'] / (metrics['TN'] + metrics['FP'])\n",
    "\n",
    "    # Positive predictive value (Precision)\n",
    "    metrics['PPV'] = metrics['TP'] / (metrics['TP'] + metrics['FP'])\n",
    "\n",
    "    # Negative predictive value\n",
    "    metrics['NPV'] = metrics['TN'] / (metrics['TN'] + metrics['FN'])\n",
    "\n",
    "    # False negative rate (Miss rate)\n",
    "    metrics['FNR'] = 1 -  metrics['TPR']\n",
    "\n",
    "    # False positive rate (Fall-out)\n",
    "    metrics['FPR'] = 1 - metrics['TNR']\n",
    "\n",
    "    # False discovery rate\n",
    "    metrics['FDR'] = 1 - metrics['PPV']\n",
    "\n",
    "    # False omission rate\n",
    "    metrics['FOR'] = 1 - metrics['NPV']\n",
    "\n",
    "    # Accuracy\n",
    "    metrics['ACC'] = (metrics['TP'] + metrics['TN']) / \\\n",
    "                                (metrics['TP'] + \n",
    "                                 metrics['TN'] + \n",
    "                                 metrics['FP'] + \n",
    "                                 metrics['FN'])\n",
    "\n",
    "    # F1 Score (also known as DSC, Sørensen–Dice coefficient, ...)\n",
    "    #metrics['F1S'] = 2 * (metrics['PPV'] * metrics['TPR']) / \\\n",
    "    #                                (metrics['PPV'] + metrics['TPR'])\n",
    "    metrics['F1S'] = (2*metrics['TP']) / (2*metrics['TP'] + metrics['FP'] + metrics['FN'])\n",
    "\n",
    "    # Matthews correlation coefficient\n",
    "    # The MCC can be more appropriate when negatives actually mean something,\n",
    "    # and can be more useful in other ways.\n",
    "    metrics['MCC'] = ((metrics['TP'] * metrics['TN']) - (metrics['FP'] * metrics['FN'])) / \\\n",
    "                        np.sqrt(\n",
    "                            (metrics['TP'] + metrics['FP']) *\n",
    "                            (metrics['TP'] + metrics['FN']) *\n",
    "                            (metrics['TN'] + metrics['FP']) *\n",
    "                            (metrics['TN'] + metrics['FN']))\n",
    "\n",
    "    # Compute Hausdorff distance\n",
    "    D = Distance()\n",
    "    if th is not None:\n",
    "        try:\n",
    "            metrics['HD'] = D._eucl_max(nib.load(original_path),\n",
    "                                        nib.Nifti1Image(predicted_data, nib.load(predicted_path).affine))\n",
    "        except:\n",
    "            metrics['HD'] = float('nan')\n",
    "    else:\n",
    "        metrics['HD'] = D._eucl_max(nib.load(original_path), nib.load(predicted_path))\n",
    "\n",
    "    # Compute Jaccard index\n",
    "    metrics['JI'] = metrics['TP'] / (metrics['FN'] + metrics['FP'] + metrics['TP'])\n",
    "\n",
    "    # Informedness or Bookmaker informedness\n",
    "    metrics['BM'] = metrics['TPR'] + metrics['TNR'] - 1\n",
    "\n",
    "    #Markedness\n",
    "    metrics['MK'] = metrics['PPV'] + metrics['NPV'] - 1\n",
    "\n",
    "    \n",
    "    return(metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir('/home/uziel/DISS')\n",
    "#os.chdir('/media/uziel/Pulga 2/DISS')\n",
    "# Set root of models to be post-processed\n",
    "root = \"/media/uziel/Pulga2/DISS/milestones_6\"\n",
    "model_variant = 'DM_V4_[0-4]' # choose model variant. Eg. \"DM_V0_[0-4]\".\n",
    "tmp = model_variant.split('_')\n",
    "if len(tmp) == 3:\n",
    "    model_name = tmp[1]\n",
    "elif len(tmp) == 4:\n",
    "    model_name = tmp[1] + '_' + tmp[2]\n",
    "else:\n",
    "    model_name = tmp[1] + '_' + tmp[2] + '_' + tmp[3]\n",
    "    \n",
    "# Load all trained models (k-folds) of model_variant\n",
    "trained_models = sorted(glob(os.path.join(root, model_variant)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POSTPROCESSING** for test cases\n",
    "\n",
    "Upsample predicted labels and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "##### POSTPROCESSING FOR K-FOLD CROSS-VALIDATION MODELS (0) ######\n",
    "##################################################################\n",
    "\n",
    "root_data = './data/ISLES2017/training'\n",
    "root_data_processed = './data_processed/ISLES2017/training'\n",
    "test_results = {}\n",
    "\n",
    "for model in trained_models:\n",
    "    root_1 = os.path.join(model, 'output/predictions/testSession/predictions')\n",
    "    root_2 = os.path.dirname(root_1)\n",
    "    \n",
    "    # Load label predictions\n",
    "    preds = sorted(glob(os.path.join(root_1, '*Segm.nii.gz')))\n",
    "    # Load probability maps of background\n",
    "    pmap_0 = sorted(glob(os.path.join(root_1, '*ProbMapClass0.nii.gz')))\n",
    "    # Load probability maps of foreground\n",
    "    pmap_1 = sorted(glob(os.path.join(root_1, '*ProbMapClass1.nii.gz')))\n",
    "    \n",
    "    test_results[os.path.basename(model)] = []\n",
    "    \n",
    "    # resize its prediction for final result validation\n",
    "    for i in range(len(preds)):\n",
    "        # Find subject that contains the code in pred.\n",
    "        subject = sorted([y\n",
    "                          for x in os.walk(root_data)\n",
    "                          for y in glob(os.path.join(x[0], '*'))\n",
    "                          if os.path.basename(preds[i]).split('_')[-2].split('.')[-1] in y\n",
    "                         ])[0].split('/')[-2]\n",
    "\n",
    "        subject_channels = sorted([y\n",
    "                                   for x in os.walk(os.path.join(root_data, subject))\n",
    "                                   for y in glob(os.path.join(x[0], '*MR_*.nii'))\n",
    "                                   if '4DPWI' not in y\n",
    "                                  ])\n",
    "        \n",
    "        subject_label = sorted([y\n",
    "                                for x in os.walk(os.path.join(root_data, subject))\n",
    "                                for y in glob(os.path.join(x[0], '*OT*.nii'))\n",
    "                               ])[0]\n",
    "\n",
    "        subject_processed = sorted([y\n",
    "                                    for x in os.walk(root_data_processed)\n",
    "                                    for y in glob(os.path.join(x[0], '*'))\n",
    "                                    if os.path.basename(preds[i]).split('_')[-2].split('.')[-1] in y\n",
    "                                   ])[0].split('/')[-2]\n",
    "        \n",
    "        subject_mask = sorted([y\n",
    "                               for x in os.walk(os.path.join(root_data_processed, subject_processed))\n",
    "                               for y in glob(os.path.join(x[0], '*mask*'))\n",
    "                              ])[0]\n",
    "        \n",
    "        # Load ADC channel as reference\n",
    "        original_img = nib.load(subject_channels[0])\n",
    "\n",
    "        # Load predictions and prob maps\n",
    "        pred_img = nib.load(preds[i])\n",
    "        pmap_0_img = nib.load(pmap_0[i])\n",
    "        pmap_1_img = nib.load(pmap_1[i])\n",
    "        \n",
    "        # Upsample to original size\n",
    "        pred_img = resample_img(pred_img,\n",
    "                                original_img.affine,\n",
    "                                original_img.shape,\n",
    "                                interpolation='nearest')\n",
    "        \n",
    "        pmap_0_img = resample_img(pmap_0_img,\n",
    "                                  original_img.affine,\n",
    "                                  original_img.shape,\n",
    "                                  interpolation='continuous')\n",
    "        \n",
    "        pmap_1_img = resample_img(pmap_1_img,\n",
    "                                  original_img.affine,\n",
    "                                  original_img.shape,\n",
    "                                  interpolation='continuous')\n",
    "        \n",
    "        # Load subject mask\n",
    "        mask_img = nib.load(subject_mask)\n",
    "        \n",
    "        # Upsample to original size\n",
    "        mask_img = resample_img(mask_img,\n",
    "                                original_img.affine,\n",
    "                                original_img.shape,\n",
    "                                interpolation='nearest')\n",
    "        \n",
    "        # Save prediction\n",
    "        pred_path = os.path.join(root_2, \"_\".join(os.path.basename(preds[i]).split('_')[:-1]) + '.pred.nii')\n",
    "        pmap_0_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_0[i]).split('_')[:-1]) + '.pmap_0.nii')\n",
    "        pmap_1_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_1[i]).split('_')[:-1]) + '.pmap_1.nii')\n",
    "        mask_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_1[i]).split('_')[:-1]) + '.mask.nii')\n",
    "        \n",
    "        nib.save(pred_img, pred_path)\n",
    "        nib.save(pmap_0_img, pmap_0_path)\n",
    "        nib.save(pmap_1_img, pmap_1_path)\n",
    "        nib.save(mask_img, mask_path)\n",
    "        \n",
    "        # Compute metrics between original and predicted label\n",
    "        metrics = get_metrics(subject_label, pred_path, mask_path)\n",
    "        \n",
    "        test_results[os.path.basename(model)].append([subject,\n",
    "                                                      subject_channels,\n",
    "                                                      subject_label,\n",
    "                                                      pred_path,\n",
    "                                                      pmap_0_path,\n",
    "                                                      pmap_1_path,\n",
    "                                                      mask_path,\n",
    "                                                      metrics])\n",
    "        \n",
    "    # Save model results\n",
    "    with open(os.path.join(model, 'test_results.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_results[os.path.basename(model)], output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    # Compute mean and std of model subjects predictions' metrics\n",
    "    metrics = np.array(test_results[os.path.basename(model)])[:,7]\n",
    "    test_metrics = {}\n",
    "    test_metrics['mean'] = {k : np.mean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    test_metrics['std'] = {k : np.std([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    \n",
    "    # Save each model's metrics\n",
    "    with open(os.path.join(model, 'test_metrics.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_metrics, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all models' results\n",
    "with open(os.path.join(root, model_name + '_test_results.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_results, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each model's metrics, compute mean and std. This is the final result of an experiment, and determines its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "test_metrics['mean'] = {k : np.mean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "test_metrics['std'] = {k : np.std([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics\n",
    "with open(os.path.join(root, model_name + '_test_metrics.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_metrics, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC CURVE** for test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_fpr = {}\n",
    "model_mean_tpr = {}\n",
    "model_mean_auc = {}\n",
    "for model in trained_models:\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, _, _ in test_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    \n",
    "    model_mean_fpr[os.path.basename(model)] = fpr\n",
    "    model_mean_tpr[os.path.basename(model)] = tpr\n",
    "    model_mean_auc[os.path.basename(model)] = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "lw = 2\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for model in trained_models:\n",
    "    tprs.append(interp(mean_fpr, model_mean_fpr[os.path.basename(model)], model_mean_tpr[os.path.basename(model)]))\n",
    "    aucs.append(model_mean_auc[os.path.basename(model)])\n",
    "    plt.plot(model_mean_fpr[os.path.basename(model)], model_mean_tpr[os.path.basename(model)], lw=1, alpha=0.3,\n",
    "             label = 'Fold {0} (AUC = {1:0.2f})'\n",
    "             ''.format(os.path.basename(model).split('_')[-1], model_mean_auc[os.path.basename(model)]))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Luck', alpha=.8)\n",
    "plt.plot([0, 1], [1, 0], 'k:', lw=lw, label = 'EER')\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "plt.xlabel('FPR', size=15)\n",
    "plt.ylabel('TPR', size=15)\n",
    "plt.title('ROC curve (' + model_name + ')')\n",
    "plt.legend(loc='lower right', fontsize=8)\n",
    "plt.savefig(os.path.join(root, model_name + '_test_roc.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRECISION-RECALL CURVE** for test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_precision = {}\n",
    "model_mean_recall = {}\n",
    "model_mean_ap = {}\n",
    "for model in trained_models:\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, _, _ in test_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    average_precision = average_precision_score(y_true, y_pred)\n",
    "    \n",
    "    model_mean_precision[os.path.basename(model)] = precision\n",
    "    model_mean_recall[os.path.basename(model)] = recall\n",
    "    model_mean_ap[os.path.basename(model)] = average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('F1S={0:0.1f}'.format(f_score), xy=(0.8, y[45] + 0.02))\n",
    "    \n",
    "lines.append(l)\n",
    "labels.append('iso-F1S curves')\n",
    "lw = 2\n",
    "for model in trained_models:\n",
    "    l, = plt.plot(model_mean_recall[os.path.basename(model)],\n",
    "                  model_mean_precision[os.path.basename(model)],\n",
    "                  lw=lw)\n",
    "    lines.append(l)\n",
    "    labels.append('Fold {0} (AP = {1:0.2f})'\n",
    "                  ''.format(os.path.basename(model).split('_')[-1],\n",
    "                            model_mean_ap[os.path.basename(model)]))\n",
    "\n",
    "#fig = plt.gcf()\n",
    "#fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('Recall (TPR)', size=15)\n",
    "plt.ylabel('Precision (PPV)', size=15)\n",
    "plt.title('PR curve (' + model_name + ')')\n",
    "plt.legend(lines, labels, loc='lower left', fontsize=8)\n",
    "plt.savefig(os.path.join(root, model_name + '_test_pr.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POSTPROCESSING** for validation cases\n",
    "\n",
    "Upsample predicted labels and compute validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "##### POSTPROCESSING FOR K-FOLD CROSS-VALIDATION MODELS (0) ######\n",
    "##################################################################\n",
    "\n",
    "root_data = './data/ISLES2017/training'\n",
    "root_data_processed = './data_processed/ISLES2017/training'\n",
    "val_results = {}\n",
    "\n",
    "for model in trained_models:\n",
    "    root_1 = os.path.join(model, 'output/predictions/valSession/predictions')\n",
    "    root_2 = os.path.dirname(root_1)\n",
    "    \n",
    "    # Load label predictions\n",
    "    preds = sorted(glob(os.path.join(root_1, '*Segm.nii.gz')))\n",
    "    # Load probability maps of background\n",
    "    pmap_0 = sorted(glob(os.path.join(root_1, '*ProbMapClass0.nii.gz')))\n",
    "    # Load probability maps of foreground\n",
    "    pmap_1 = sorted(glob(os.path.join(root_1, '*ProbMapClass1.nii.gz')))\n",
    "    \n",
    "    val_results[os.path.basename(model)] = []\n",
    "    \n",
    "    # resize its prediction for final result validation\n",
    "    for i in range(len(preds)):\n",
    "        # Find subject that contains the code in pred.\n",
    "        subject = sorted([y\n",
    "                          for x in os.walk(root_data)\n",
    "                          for y in glob(os.path.join(x[0], '*'))\n",
    "                          if os.path.basename(preds[i]).split('_')[-2].split('.')[-1] in y\n",
    "                         ])[0].split('/')[-2]\n",
    "\n",
    "        subject_channels = sorted([y\n",
    "                                   for x in os.walk(os.path.join(root_data, subject))\n",
    "                                   for y in glob(os.path.join(x[0], '*MR_*.nii'))\n",
    "                                   if '4DPWI' not in y\n",
    "                                  ])\n",
    "        \n",
    "        subject_label = sorted([y\n",
    "                                for x in os.walk(os.path.join(root_data, subject))\n",
    "                                for y in glob(os.path.join(x[0], '*OT*.nii'))\n",
    "                               ])[0]\n",
    "\n",
    "        subject_processed = sorted([y\n",
    "                                    for x in os.walk(root_data_processed)\n",
    "                                    for y in glob(os.path.join(x[0], '*'))\n",
    "                                    if os.path.basename(preds[i]).split('_')[-2].split('.')[-1] in y\n",
    "                                   ])[0].split('/')[-2]\n",
    "        \n",
    "        subject_mask = sorted([y\n",
    "                               for x in os.walk(os.path.join(root_data_processed, subject_processed))\n",
    "                               for y in glob(os.path.join(x[0], '*mask*'))\n",
    "                              ])[0]\n",
    "        \n",
    "        # Load ADC channel as reference\n",
    "        original_img = nib.load(subject_channels[0])\n",
    "\n",
    "        # Load predictions and prob maps\n",
    "        pred_img = nib.load(preds[i])\n",
    "        pmap_0_img = nib.load(pmap_0[i])\n",
    "        pmap_1_img = nib.load(pmap_1[i])\n",
    "        \n",
    "        # Upsample to original size\n",
    "        pred_img = resample_img(pred_img,\n",
    "                                original_img.affine,\n",
    "                                original_img.shape,\n",
    "                                interpolation='nearest')\n",
    "        \n",
    "        pmap_0_img = resample_img(pmap_0_img,\n",
    "                                  original_img.affine,\n",
    "                                  original_img.shape,\n",
    "                                  interpolation='continuous')\n",
    "        \n",
    "        pmap_1_img = resample_img(pmap_1_img,\n",
    "                                  original_img.affine,\n",
    "                                  original_img.shape,\n",
    "                                  interpolation='continuous')\n",
    "        \n",
    "        # Load subject mask\n",
    "        mask_img = nib.load(subject_mask)\n",
    "        \n",
    "        # Upsample to original size\n",
    "        mask_img = resample_img(mask_img,\n",
    "                                original_img.affine,\n",
    "                                original_img.shape,\n",
    "                                interpolation='nearest')\n",
    "        \n",
    "        # Save prediction\n",
    "        pred_path = os.path.join(root_2, \"_\".join(os.path.basename(preds[i]).split('_')[:-1]) + '.pred.nii')\n",
    "        pmap_0_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_0[i]).split('_')[:-1]) + '.pmap_0.nii')\n",
    "        pmap_1_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_1[i]).split('_')[:-1]) + '.pmap_1.nii')\n",
    "        mask_path = os.path.join(root_2, \"_\".join(os.path.basename(pmap_1[i]).split('_')[:-1]) + '.mask.nii')\n",
    "        \n",
    "        nib.save(pred_img, pred_path)\n",
    "        nib.save(pmap_0_img, pmap_0_path)\n",
    "        nib.save(pmap_1_img, pmap_1_path)\n",
    "        nib.save(mask_img, mask_path)\n",
    "        \n",
    "        # Compute metrics between original and predicted label\n",
    "        metrics = get_metrics(subject_label, pred_path, mask_path)\n",
    "        \n",
    "        val_results[os.path.basename(model)].append([subject,\n",
    "                                                     subject_channels,\n",
    "                                                     subject_label,\n",
    "                                                     pred_path,\n",
    "                                                     pmap_0_path,\n",
    "                                                     pmap_1_path,\n",
    "                                                     mask_path,\n",
    "                                                     metrics])\n",
    "        \n",
    "    # Save model results\n",
    "    with open(os.path.join(model, 'val_results.pkl'), 'wb') as output:\n",
    "        pickle.dump(val_results[os.path.basename(model)], output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    # Compute mean and std of model subjects predictions' metrics\n",
    "    metrics = np.array(val_results[os.path.basename(model)])[:,7]\n",
    "    val_metrics = {}\n",
    "    val_metrics['mean'] = {k : np.mean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    val_metrics['std'] = {k : np.std([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    \n",
    "    # Save each model's metrics\n",
    "    with open(os.path.join(model, 'val_metrics.pkl'), 'wb') as output:\n",
    "        pickle.dump(val_metrics, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all models' results\n",
    "with open(os.path.join(root, model_name + '_val_results.pkl'), 'wb') as output:\n",
    "    pickle.dump(val_results, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each model's metrics, compute mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'val_metrics.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "val_metrics['mean'] = {k : np.mean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "val_metrics['std'] = {k : np.std([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics\n",
    "with open(os.path.join(root, model_name + '_val_metrics.pkl'), 'wb') as output:\n",
    "    pickle.dump(val_metrics, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot original and predicted labels for validation cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC CURVE** for validation cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_fpr = {}\n",
    "model_mean_tpr = {}\n",
    "model_mean_auc = {}\n",
    "for model in trained_models:\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, _, _ in val_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    \n",
    "    model_mean_fpr[os.path.basename(model)] = fpr\n",
    "    model_mean_tpr[os.path.basename(model)] = tpr\n",
    "    model_mean_auc[os.path.basename(model)] = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "lw = 2\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for model in trained_models:\n",
    "    tprs.append(interp(mean_fpr, model_mean_fpr[os.path.basename(model)], model_mean_tpr[os.path.basename(model)]))\n",
    "    aucs.append(model_mean_auc[os.path.basename(model)])\n",
    "    plt.plot(model_mean_fpr[os.path.basename(model)], model_mean_tpr[os.path.basename(model)], lw=1, alpha=0.3,\n",
    "             label = 'Fold {0} (AUC = {1:0.2f})'\n",
    "             ''.format(os.path.basename(model).split('_')[-1], model_mean_auc[os.path.basename(model)]))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Luck', alpha=.8)\n",
    "plt.plot([0, 1], [1, 0], 'k:', lw=lw, label = 'EER')\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "plt.xlabel('FPR', size=15)\n",
    "plt.ylabel('TPR', size=15)\n",
    "plt.title('ROC curve (' + model_name + ')')\n",
    "plt.legend(loc='lower right', fontsize=8)\n",
    "plt.savefig(os.path.join(root, model_name + '_val_roc.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRECISION-RECALL CURVE** for validation cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_precision = {}\n",
    "model_mean_recall = {}\n",
    "model_mean_ap = {}\n",
    "for model in trained_models:\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, _, _ in val_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    average_precision = average_precision_score(y_true, y_pred)\n",
    "    \n",
    "    model_mean_precision[os.path.basename(model)] = precision\n",
    "    model_mean_recall[os.path.basename(model)] = recall\n",
    "    model_mean_ap[os.path.basename(model)] = average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('F1S={0:0.1f}'.format(f_score), xy=(0.8, y[45] + 0.02))\n",
    "    \n",
    "lines.append(l)\n",
    "labels.append('iso-F1S curves')\n",
    "lw = 2\n",
    "for model in trained_models:\n",
    "    l, = plt.plot(model_mean_recall[os.path.basename(model)],\n",
    "                  model_mean_precision[os.path.basename(model)],\n",
    "                  lw=lw)\n",
    "    lines.append(l)\n",
    "    labels.append('Fold {0} (AP = {1:0.2f})'\n",
    "                  ''.format(os.path.basename(model).split('_')[-1],\n",
    "                            model_mean_ap[os.path.basename(model)]))\n",
    "\n",
    "#fig = plt.gcf()\n",
    "#fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('Recall (TPR)', size=15)\n",
    "plt.ylabel('Precision (PPV)', size=15)\n",
    "plt.title('PR curve (' + model_name + ')')\n",
    "plt.legend(lines, labels, loc='lower left', fontsize=8)\n",
    "plt.savefig(os.path.join(root, model_name + '_val_pr.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THRESHOLD TUNING V0**\n",
    "\n",
    "Use precision-recall curve on validation cases to maximize F1S on test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_metrics_tht_v0 = {}\n",
    "for model in trained_models:\n",
    "    # Compute best average threshold for validation cases\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, mask_path, _ in val_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    # Optimal threshold is where precision * recall is maximum\n",
    "    tmp = precision * recall        \n",
    "    # The closest point is the furthest from bottom-left corner\n",
    "    idx = np.argwhere(tmp == np.max(tmp))\n",
    "    th_op = thresholds[idx]\n",
    "    \n",
    "    all_test_metrics_tht_v0[os.path.basename(model)] = []\n",
    "    # Recompute test metrics with optimal threshold from validation cases\n",
    "    for _, _, subject_label, _, _, pmap_1_path, mask_path, _ in test_results[os.path.basename(model)]:\n",
    "        original_data = nib.load(subject_label).get_data()\n",
    "        predicted_data = nib.load(pmap_1_path).get_data()\n",
    "        \n",
    "        # Compute new metrics after new threshold\n",
    "        metrics = get_metrics(subject_label, pmap_1_path, mask_path, th_op)\n",
    "        metrics['TH_OP'] = th_op\n",
    "        all_test_metrics_tht_v0[os.path.basename(model)].append(metrics)\n",
    "        \n",
    "    metrics = np.array(all_test_metrics_tht_v0[os.path.basename(model)])\n",
    "    test_metrics_tht_v0 = {}\n",
    "    test_metrics_tht_v0['mean'] = {k : np.nanmean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    test_metrics_tht_v0['std'] = {k : np.nanstd([t[k] for t in metrics]) for k in metrics[0]}\n",
    "\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v0.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_metrics_tht_v0, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all metrics after threshold tuning v0 for future reference\n",
    "with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'wb') as output:\n",
    "    pickle.dump(all_test_metrics_tht_v0, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each model's metrics after **threshold tuning v0**, compute mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v0.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "test_metrics_tht_v0['mean'] = {k : np.nanmean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "test_metrics_tht_v0['std'] = {k : np.nanstd([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics after tht_v0\n",
    "with open(os.path.join(root, model_name + '_test_metrics_tht_v0.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_metrics_tht_v0, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THRESHOLD TUNING V1**\n",
    "\n",
    "Use ROC curve on validation cases to maximize BM on test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_metrics_tht_v1 = {}\n",
    "for model in trained_models:\n",
    "    # Compute best average threshold for validation cases\n",
    "    original_data = []\n",
    "    predicted_data = []\n",
    "    for _, _, subject_label, _, _, pmap_1_path, mask_path, _ in val_results[os.path.basename(model)]:\n",
    "        original_data.append(nib.load(subject_label).get_data().ravel())\n",
    "        predicted_data.append(nib.load(pmap_1_path).get_data().ravel())\n",
    "\n",
    "    # Join all subjects to perform micro-average\n",
    "    y_true = list(chain.from_iterable(original_data))\n",
    "    y_pred = list(chain.from_iterable(predicted_data))\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    # Optimal threshold is where tpr - fpr is maximum\n",
    "    d = tpr - fpr\n",
    "    idx = np.argwhere(d == np.max(d))\n",
    "    th_op = thresholds[idx]\n",
    "    \n",
    "    all_test_metrics_tht_v1[os.path.basename(model)] = []\n",
    "    # Recompute test metrics with optimal threshold from validation cases\n",
    "    for _, _, subject_label, _, _, pmap_1_path, mask_path, _ in test_results[os.path.basename(model)]:\n",
    "        original_data = nib.load(subject_label).get_data()\n",
    "        predicted_data = nib.load(pmap_1_path).get_data()\n",
    "        \n",
    "        # Compute new metrics after new threshold\n",
    "        metrics = get_metrics(subject_label, pmap_1_path, mask_path, th_op)\n",
    "        metrics['TH_OP'] = th_op\n",
    "        all_test_metrics_tht_v1[os.path.basename(model)].append(metrics)\n",
    "        \n",
    "    metrics = np.array(all_test_metrics_tht_v1[os.path.basename(model)])\n",
    "    test_metrics_tht_v1 = {}\n",
    "    test_metrics_tht_v1['mean'] = {k : np.nanmean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    test_metrics_tht_v1['std'] = {k : np.nanstd([t[k] for t in metrics]) for k in metrics[0]}\n",
    "\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v1.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_metrics_tht_v1, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all metrics after threshold tuining for future reference\n",
    "with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'wb') as output:\n",
    "    pickle.dump(all_test_metrics_tht_v1, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each model's metrics after **threshold tuning v1**, compute mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v1.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "test_metrics_tht_v1['mean'] = {k : np.nanmean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "test_metrics_tht_v1['std'] = {k : np.nanstd([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics after tht_v1\n",
    "with open(os.path.join(root, model_name + '_test_metrics_tht_v1.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_metrics_tht_v1, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILL HOLES**\n",
    "\n",
    "Apply morphological operation of closing to fill holes in the predicted label (predicted segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define struct\n",
    "#struct = ndimage.generate_binary_structure(3, 3)\n",
    "struct = ball(3)\n",
    "all_test_metrics_de = {}\n",
    "for model in trained_models:\n",
    "    all_test_metrics_de[os.path.basename(model)] = []\n",
    "    with open(os.path.join(model, 'test_metrics_tht_v0.pkl'), 'rb') as input:\n",
    "        metrics = pickle.load(input)\n",
    "        th = metrics['mean']['TH_OP']\n",
    "        \n",
    "    iterations = []\n",
    "    for _, _, subject_label, pred_label, _, pmap_1_path, mask_path, _ in val_results[os.path.basename(model)]:\n",
    "        original_data = nib.load(subject_label).get_data()\n",
    "        predicted_data = nib.load(pmap_1_path).get_data()\n",
    "        predicted_label = nib.load(pred_label).get_data()\n",
    "        \n",
    "        scores = []\n",
    "        for i in range(1,11):\n",
    "            try:\n",
    "                # Apply morphological operation of closing\n",
    "                #cl_data = binary_closing(predicted_data > th, struct, iterations=i)\n",
    "                cl_data = binary_closing(predicted_label, struct, iterations=i)\n",
    "                # Compute F1S\n",
    "                scores.append(f1_score(original_data.ravel(), cl_data.ravel()))\n",
    "            except:\n",
    "                break\n",
    "        # Get number of iterations that achieved max F1S\n",
    "        idx = np.argwhere(scores == np.max(scores))[0]\n",
    "        iterations.append(idx+1)        \n",
    "        \n",
    "    mean_iter = int(np.floor(np.mean(iterations)))\n",
    "    for _, _, subject_label, pred_label, _, pmap_1_path, mask_path, _ in test_results[os.path.basename(model)]:\n",
    "        original_data = nib.load(subject_label).get_data()\n",
    "        predicted_data = nib.load(pmap_1_path).get_data()\n",
    "        predicted_label = nib.load(pred_label).get_data()\n",
    "        \n",
    "        # Apply morphological operation of closing\n",
    "        #img = binary_closing(predicted_data > th, struct, iterations=mean_iter)\n",
    "        img = binary_closing(predicted_label, struct, iterations=mean_iter)\n",
    "        # Save image temporarly\n",
    "        temp_path = 'temp.nii.gz'\n",
    "        nib.save(nib.Nifti1Image(img.astype(int), nib.load(subject_label).affine), temp_path)\n",
    "        \n",
    "        # Recompute metrics\n",
    "        metrics = get_metrics(subject_label, temp_path, mask_path, 0)\n",
    "        metrics['TH_OP'] = 0\n",
    "        metrics['N_iter'] = mean_iter\n",
    "        all_test_metrics_de[os.path.basename(model)].append(metrics)\n",
    "        \n",
    "    metrics = np.array(all_test_metrics_de[os.path.basename(model)])\n",
    "    test_metrics_de = {}\n",
    "    test_metrics_de['mean'] = {k : np.nanmean([t[k] for t in metrics]) for k in metrics[0]}\n",
    "    test_metrics_de['std'] = {k : np.nanstd([t[k] for t in metrics]) for k in metrics[0]}\n",
    "\n",
    "    with open(os.path.join(model, 'test_metrics_de.pkl'), 'wb') as output:\n",
    "        pickle.dump(test_metrics_de, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save all metrics after dilation-erosion for future reference\n",
    "with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'wb') as output:\n",
    "    pickle.dump(all_test_metrics_de, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics_de.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "test_metrics_de['mean'] = {k : np.nanmean([t['mean'][k] for t in metrics]) for k in metrics[0]['mean']}\n",
    "test_metrics_de['std'] = {k : np.nanstd([t['std'][k] for t in metrics]) for k in metrics[0]['std']}\n",
    "\n",
    "# Save final experiment metrics after tht_v1\n",
    "with open(os.path.join(root, model_name + '_test_metrics_de.pkl'), 'wb') as output:\n",
    "    pickle.dump(test_metrics_de, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESS TRAINING AND VALIDATION RESULTS**\n",
    "\n",
    "Plot and save training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in trained_models:\n",
    "    # Plot and save training progress\n",
    "    os.system(\"python ischleseg/deepmedic/plotSaveTrainingProgress.py \" +\n",
    "              os.path.join(model, \"output/logs/trainSession.txt -d -m 20 -s\"))\n",
    "    # Move files to the corresponding model directory\n",
    "    os.system(\"mv trainingProgress.pdf \" + os.path.join(model, 'trainingProgress_' + os.path.basename(model) + '.pdf'))\n",
    "    os.system(\"mv trainingProgress.pkl \" + os.path.join(model, 'trainingProgress.pkl'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training metrics and compute mean and variance between models (includes training and validation metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"measuredMetricsFromAllExperiments\"\n",
    "# 1st dimension: \"Validation\" (0), \"Training\" (1)\n",
    "# 2nd dimension: ? (0)\n",
    "# 3rd dimension: \"Mean Accuracy\" (0), \"Sensitivity\" (1), \"Specificity\" (2), \"DSC (samples)\" (3), \"DSC (full-segm)\" (4)\n",
    "\n",
    "metrics = {}\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'trainingProgress.pkl'), 'rb') as input:\n",
    "        metrics[os.path.basename(model)] = np.array(pickle.load(input))\n",
    "        metrics[os.path.basename(model)][0,0,4] = np.array(metrics[os.path.basename(model)][0,0,4])\n",
    "        \n",
    "# Compute mean and variance of all models' variations metrics\n",
    "metrics_mean = {}\n",
    "metrics_std = {}\n",
    "metrics_values = np.array(metrics.values())\n",
    "metrics_names_0 = ['Validation', 'Training']\n",
    "metrics_names_1 = ['ACC', 'TPR', 'TNR', 'DSC (Samples)', 'DSC (full-segm)']\n",
    "\n",
    "for i in range(len(metrics_names_0)):\n",
    "    metrics_mean[metrics_names_0[i]] = {}\n",
    "    metrics_std[metrics_names_0[i]] = {}\n",
    "    for j in range(len(metrics_names_1)):\n",
    "        if i == 1 and j == 4: # Skip DSC_full for training (is never calculated)\n",
    "            metrics_mean[metrics_names_0[i]][metrics_names_1[j]] = np.zeros(35*20)\n",
    "            metrics_std[metrics_names_0[i]][metrics_names_1[j]] = np.zeros(35*20)\n",
    "            continue \n",
    "        metrics_mean[metrics_names_0[i]][metrics_names_1[j]] = np.mean(metrics_values[:,i,0,j])\n",
    "        metrics_std[metrics_names_0[i]][metrics_names_1[j]] = np.std(metrics_values[:,i,0,j])\n",
    "\n",
    "train_val_metrics = {}\n",
    "train_val_metrics['mean'] = metrics_mean\n",
    "train_val_metrics['std'] = metrics_std\n",
    "# Save final experiment progress metrics\n",
    "with open(os.path.join(root, model_name + '_train_val_metrics.pkl'), 'wb') as output:\n",
    "    pickle.dump(train_val_metrics, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot mean training and validation progress metrics of all trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for model in trained_models:\n",
    "    with open(os.path.join(model, 'test_metrics.pkl'), 'rb') as input:\n",
    "        metrics.append(pickle.load(input))\n",
    "\n",
    "plt.close('all')\n",
    "rows, cols = [2, 5]\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*3, rows*2))\n",
    "\n",
    "for ax, col in zip(axes[0], metrics_names_1):\n",
    "    ax.set_title(col, pad=15, size=12)\n",
    "\n",
    "for ax, row in zip(axes[:,0], metrics_names_0):\n",
    "    ax.set_ylabel(row, rotation='vertical', size=12)\n",
    "    ax.yaxis.set_label_coords(-0.3, 0.5)\n",
    "    \n",
    "    \n",
    "for i in range(len(metrics_names_0)):\n",
    "    for j in range(len(metrics_names_1)):       \n",
    "        upper = np.minimum(metrics_mean[metrics_names_0[i]][metrics_names_1[j]] +\n",
    "                           metrics_std[metrics_names_0[i]][metrics_names_1[j]], 1)\n",
    "        lower = np.maximum(metrics_mean[metrics_names_0[i]][metrics_names_1[j]] -\n",
    "                           metrics_std[metrics_names_0[i]][metrics_names_1[j]], 0)\n",
    "        if i == 0 and j == 4:\n",
    "            x = np.arange(0, 40, 5)\n",
    "        else:\n",
    "            x = np.arange(0, 35, 1/20.0)\n",
    "        \n",
    "        axes[i,j].plot(x, metrics_mean[metrics_names_0[i]][metrics_names_1[j]], 'r')        \n",
    "        axes[i,j].fill_between(x, lower, upper,\n",
    "                         color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "        axes[i,j].set_xlim(0, 35)\n",
    "        axes[i,j].set_ylim(0, 1.0)\n",
    "        if i == 1:\n",
    "            axes[i,j].set_xlabel('Epoch', size=13)\n",
    "        \n",
    "        if j == 2 and i == 1:\n",
    "            axes[i,j].legend(loc=(0.1, -0.7))\n",
    "        axes[i,j].yaxis.grid(True)\n",
    "\n",
    "# Save mean training and validation metrics of all trained models averaged\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.3)\n",
    "plt.savefig(os.path.join(root, model_name + '_meanTrainValProgress.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ERROR BARS** for test cases\n",
    "\n",
    "Plot [0,1] metrics error bars in a 4x3 figure. Each row represents the results of each detection step (0=network output, 1=threshold tuning v0, 2=threshold tuning v1, 3=fill holes). Each column represents the error bars for the three groups of strokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Load all test cases from all folds (43)\n",
    "error_bars_metrics = {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                      '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                      '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                      '3':{'1':[], '2':[], '3':[], '4':[]}}\n",
    "# Define keys that will be part of the error bars\n",
    "keys = ['F1S', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        \n",
    "        subject, _, _, _, _, _, _, metrics_0 = all_test_metrics[os.path.basename(model)][i]\n",
    "        stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "        # Store only the metrics that go from 0 to 1\n",
    "        # 4 is the 'ALL' category\n",
    "        error_bars_metrics['0'][stroke_type].append([metrics_0[key] for key in keys])\n",
    "        error_bars_metrics['0']['4'].append([metrics_0[key] for key in keys])\n",
    "\n",
    "        metrics_1 = all_test_metrics_tht_v0[os.path.basename(model)][i]\n",
    "        error_bars_metrics['1'][stroke_type].append([metrics_1[key] for key in keys])\n",
    "        error_bars_metrics['1']['4'].append([metrics_1[key] for key in keys])\n",
    "        \n",
    "        metrics_2 = all_test_metrics_tht_v1[os.path.basename(model)][i]\n",
    "        error_bars_metrics['2'][stroke_type].append([metrics_2[key] for key in keys])\n",
    "        error_bars_metrics['2']['4'].append([metrics_2[key] for key in keys])\n",
    "        \n",
    "        metrics_3 = all_test_metrics_de[os.path.basename(model)][i]\n",
    "        error_bars_metrics['3'][stroke_type].append([metrics_3[key] for key in keys])\n",
    "        error_bars_metrics['3']['4'].append([metrics_3[key] for key in keys])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = ['Base', 'THT0', 'THT1', 'FH']\n",
    "col_labels = ['Lacunar/\\nSubcortical', 'Small cortical', 'Big cortical/\\nMain artery', 'All']\n",
    "\n",
    "x_labels = ['DSC', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "plt.close('all')\n",
    "rows, cols = [4, 4]\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(3*cols, rows*2))\n",
    "\n",
    "for ax, col in zip(axes[0], col_labels):\n",
    "    ax.set_title(col, pad=20, size=15)\n",
    "\n",
    "for ax, row in zip(axes[:,0], row_labels):\n",
    "    ax.set_ylabel(row, rotation='vertical', size=15)\n",
    "    ax.yaxis.set_label_coords(-0.3, 0.5)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(1,cols+1):\n",
    "        # Compute mean and confidence interval\n",
    "        metrics = error_bars_metrics[str(i)][str(j)]\n",
    "        mean = np.mean(metrics, axis=0)\n",
    "        confidence_interval = st.t.interval(0.95, len(metrics[0])-1,\n",
    "                                            loc=mean, scale=st.sem(metrics, axis=0))\n",
    "        differences = (abs(confidence_interval[0] - mean), abs(confidence_interval[1] - mean))\n",
    "        \n",
    "        # Plot error bar\n",
    "        axes[i,j-1].grid()\n",
    "        axes[i,j-1].set_ylim([0,1])\n",
    "        axes[i,j-1].tick_params(axis='x', width=10)\n",
    "        (_, caps, _) = axes[i,j-1].errorbar(x_labels, mean, differences,\n",
    "                                    color='red', mew=5,\n",
    "                                    fmt='o', markersize=3, capsize=10)\n",
    "\n",
    "        for cap in caps:\n",
    "            cap.set_markeredgewidth(1)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "plt.savefig(os.path.join(root, model_name + '_test_error_bars.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISUAL SEGMENTATION COMPARISON**\n",
    "\n",
    "Plot the predicted segmentations for each phase. Rows are subjects, columns phases. Plot three times with the best 5 results of each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Set best cut in z coordinate for each subject\n",
    "tr_cut_coords = {'training_1': [11], 'training_2': [16], 'training_4': [13], 'training_5': [11], 'training_6': [16],\n",
    "                 'training_7': [15], 'training_8': [15], 'training_9': [14], 'training_10': [12], 'training_11': [9],\n",
    "                 'training_12': [12], 'training_13': [15], 'training_14': [15], 'training_15': [16], 'training_16': [16],\n",
    "                 'training_18': [9], 'training_19': [15], 'training_20': [15], 'training_21': [10], 'training_22': [13],\n",
    "                 'training_23': [15], 'training_24': [12], 'training_26': [14], 'training_27': [11], 'training_28': [21],\n",
    "                 'training_30': [14], 'training_31': [19], 'training_32': [14], 'training_33': [18], 'training_35': [17],\n",
    "                 'training_36': [16], 'training_37': [15], 'training_38': [15], 'training_39': [10], 'training_40': [11],\n",
    "                 'training_41': [11], 'training_42': [12], 'training_43': [8], 'training_44': [14], 'training_45': [9],\n",
    "                 'training_46': [12], 'training_47': [15], 'training_48': [12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all test cases from all folds (43)\n",
    "base_metrics = {'1':[], '2':[], '3':[]}\n",
    "subjects_info = {'1':[], '2':[], '3':[]}\n",
    "\n",
    "# Define keys\n",
    "keys = ['F1S']\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        subject, subject_channels, subject_label, pred_path, _, pmap_1_path, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "        stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "        subjects_info[stroke_type].append([subject, subject_channels, subject_label, pred_path, pmap_1_path])\n",
    "        \n",
    "        f1s_0 = metrics['F1S']\n",
    "        f1s_1 = all_test_metrics_tht_v0[os.path.basename(model)][i]['F1S']\n",
    "        f1s_2 = all_test_metrics_tht_v1[os.path.basename(model)][i]['F1S']\n",
    "        f1s_3 = all_test_metrics_de[os.path.basename(model)][i]['F1S']\n",
    "        th_op_0 = all_test_metrics_tht_v0[os.path.basename(model)][i]['TH_OP']\n",
    "        th_op_1 = all_test_metrics_tht_v1[os.path.basename(model)][i]['TH_OP']\n",
    "        n_iter = all_test_metrics_de[os.path.basename(model)][i]['N_iter']\n",
    "        \n",
    "        base_metrics[stroke_type].append([f1s_0, f1s_1, f1s_2, f1s_3,\n",
    "                                          th_op_0, th_op_1, n_iter])\n",
    "        \n",
    "# Create all three plots\n",
    "col_labels = ['ADC', 'Ground truth', 'Base', 'THT0', 'THT1', 'FH']\n",
    "\n",
    "# generate the colors for your colormap\n",
    "color1 = colorConverter.to_rgba('white')\n",
    "\n",
    "# make the colormaps\n",
    "cmap1 = mpl.colors.LinearSegmentedColormap.from_list('my_cmap',['black','red'],256)\n",
    "\n",
    "cmap1._init() # create the _lut array, with rgba values\n",
    "\n",
    "# create your alpha array and fill the colormap with them.\n",
    "# here it is progressive, but you can create whathever you want\n",
    "alphas = np.linspace(0, 0.8, cmap1.N+3)\n",
    "cmap1._lut[:,-1] = alphas\n",
    "\n",
    "# Number of subjects to show\n",
    "n = 3\n",
    "for i in range(1,4):\n",
    "    plt.close('all')\n",
    "    rows, cols = [n,6]\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(15, n*2))\n",
    "    \n",
    "    # Get the 5 subjects with the highest F1S\n",
    "    f1s_list = [x[0] for x in base_metrics[str(i)]]\n",
    "    indexes = np.lexsort((range(len(subjects_info[str(i)])), f1s_list))[::-1]\n",
    "    all_subjects = [subjects_info[str(i)][idx] for idx in indexes][:n]    \n",
    "    row_labels = [x[0] for x in all_subjects]\n",
    "    base_metrics[str(i)] = [base_metrics[str(i)][idx] for idx in indexes][:n]\n",
    "    \n",
    "    for ax, col in zip(axes[0], col_labels):\n",
    "        ax.set_title(col, color='w', pad=30)\n",
    "\n",
    "    for ax, row in zip(axes[:,0], row_labels):\n",
    "        ax.set_ylabel(row.split('_')[-1], rotation=0, size='large', color='white')\n",
    "        ax.yaxis.set_label_coords(-0.5, 0.5)\n",
    "    \n",
    "    \n",
    "    for j in range(len(all_subjects)):\n",
    "        # Cut coords for this subject\n",
    "        cut_coords = tr_cut_coords[all_subjects[j][0]][0]\n",
    "        channel_ADC = all_subjects[j][1][0]\n",
    "        ADC_data = nib.load(channel_ADC).get_data()\n",
    "        \n",
    "        # Find best bounding box\n",
    "        data_2d = ADC_data[:,:,cut_coords]\n",
    "        idx = np.nonzero(data_2d)\n",
    "        # row_min, row_max, col_min, col_max\n",
    "        bbox = [np.min(idx[0]), np.max(idx[0]), np.min(idx[1]), np.max(idx[1])] \n",
    "        \n",
    "        # 0 - ADC Channel\n",
    "        axes[j,0].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,0].set_xlabel('z=%d' % cut_coords, color='w')\n",
    "        axes[j,0].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 1 - Ground truth\n",
    "        label_data = nib.load(all_subjects[j][2]).get_data()\n",
    "        vol = np.sum(label_data) * 0.001\n",
    "        axes[j,1].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,1].imshow(label_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.7, interpolation='none')\n",
    "        axes[j,1].set_xlabel('DSC: 1\\n%.2f cm3' % vol, color='w')\n",
    "        axes[j,1].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 2 - Base prediction\n",
    "        prediction_data = nib.load(all_subjects[j][3]).get_data()\n",
    "        vol = np.sum(prediction_data) * 0.001\n",
    "        axes[j,2].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,2].imshow(prediction_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.5, interpolation='none')\n",
    "        axes[j,2].set_xlabel('DSC: %.2f\\n%.2f cm3' % (base_metrics[str(i)][j][0], vol), color='w')\n",
    "        axes[j,2].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 3 - THT V0\n",
    "        thtv0_data = (nib.load(all_subjects[j][4]).get_data() > base_metrics[str(i)][j][4]).astype(int)\n",
    "        vol = np.sum(thtv0_data) * 0.001\n",
    "        axes[j,3].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,3].imshow(thtv0_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.5, interpolation='none')\n",
    "        axes[j,3].set_xlabel('DSC: %.2f\\n%.2f cm3' % (base_metrics[str(i)][j][1], vol), color='w')\n",
    "        axes[j,3].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 4 - THT V1\n",
    "        thtv1_data = (nib.load(all_subjects[j][4]).get_data() > base_metrics[str(i)][j][5]).astype(int)\n",
    "        vol = np.sum(thtv1_data) * 0.001\n",
    "        axes[j,4].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,4].imshow(thtv0_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.5, interpolation='none')\n",
    "        axes[j,4].set_xlabel('DSC: %.2f\\n%.2f cm3' % (base_metrics[str(i)][j][2], vol), color='w')\n",
    "        axes[j,4].xaxis.set_label_coords(0.5, -0.1)\n",
    "        \n",
    "        # 5 - Fill holes\n",
    "        struct = ball(3)\n",
    "        fh_data = binary_closing(nib.load(all_subjects[j][3]).get_data(),\n",
    "                                 struct, iterations=base_metrics[str(i)][j][6]).astype(int)\n",
    "        vol = np.sum(fh_data) * 0.001\n",
    "        axes[j,5].imshow(ADC_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, 'gray', interpolation='none')\n",
    "        axes[j,5].imshow(fh_data[bbox[0]:bbox[1],bbox[2]:bbox[3],cut_coords].T, cmap=cmap1, alpha=0.5, interpolation='none')\n",
    "        axes[j,5].set_xlabel('DSC: %.2f\\n%.2f cm3' % (base_metrics[str(i)][j][3], vol), color='w')\n",
    "        axes[j,5].xaxis.set_label_coords(0.5, -0.1)\n",
    "\n",
    "    \n",
    "        fig.subplots_adjust(hspace=0.5, wspace=-0.7)\n",
    "\n",
    "    \n",
    "    # save figure\n",
    "    fig.patch.set_facecolor('xkcd:black')\n",
    "    fig.savefig(os.path.join(root, model_name + '_test_seg_comparison_group_%d.pdf' % i),\n",
    "                bbox_inches='tight', facecolor=fig.get_facecolor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BLAND-ALTMAN PLOT**\n",
    "\n",
    "The Bland-Altman plot (Bland & Altman, 1986 and 1999), or difference plot, is a graphical method to compare two measurements techniques. In this graphical method the differences (or alternatively the ratios) between the two techniques are plotted against the averages of the two techniques. Alternatively (Krouwer, 2008) the differences can be plotted against one of the two methods, if this method is a reference or \"gold standard\" method.\n",
    "\n",
    "Horizontal lines are drawn at the mean difference, and at the limits of agreement, which are defined as the mean difference plus and minus 1.96 times the standard deviation of the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Load all test cases from all folds (43)\n",
    "bland_altman_metrics = {'0':{'1':[], '2':[], '3':[]},\n",
    "                        '1':{'1':[], '2':[], '3':[]},\n",
    "                        '2':{'1':[], '2':[], '3':[]},\n",
    "                        '3':{'1':[], '2':[], '3':[]},\n",
    "                        '4':{'1':[], '2':[], '3':[]}}\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        \n",
    "        subject, _, subject_label, pred_path, _, pmap_1_path, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "        stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "        \n",
    "        # 0 - Original\n",
    "        f1s = 1\n",
    "        vol = np.sum(nib.load(subject_label).get_data())\n",
    "        bland_altman_metrics['0'][stroke_type].append([f1s, vol])\n",
    "        \n",
    "        # 1 - Base\n",
    "        f1s = metrics['F1S']\n",
    "        vol = np.sum(nib.load(pred_path).get_data())\n",
    "        bland_altman_metrics['1'][stroke_type].append([f1s, vol])\n",
    "        \n",
    "        # 2 - THT v0\n",
    "        f1s = all_test_metrics_tht_v0[os.path.basename(model)][i]['F1S']\n",
    "        th = all_test_metrics_tht_v0[os.path.basename(model)][i]['TH_OP']\n",
    "        vol = np.sum(nib.load(pmap_1_path).get_data() > th)\n",
    "        bland_altman_metrics['2'][stroke_type].append([f1s, vol])\n",
    "        \n",
    "        # 3 - THT v1\n",
    "        f1s = all_test_metrics_tht_v1[os.path.basename(model)][i]['F1S']\n",
    "        th = all_test_metrics_tht_v1[os.path.basename(model)][i]['TH_OP']\n",
    "        vol = np.sum(nib.load(pmap_1_path).get_data() > th)\n",
    "        bland_altman_metrics['3'][stroke_type].append([f1s, vol])\n",
    "        \n",
    "        # 4 - Fill holes\n",
    "        f1s = all_test_metrics_de[os.path.basename(model)][i]['F1S']\n",
    "        N_iter = all_test_metrics_de[os.path.basename(model)][i]['N_iter']\n",
    "        struct = ball(3)\n",
    "        vol = np.sum(binary_closing(nib.load(pred_path).get_data(), struct, iterations=N_iter))\n",
    "        bland_altman_metrics['4'][stroke_type].append([f1s, vol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = ['Base', 'THT0', 'THT1', 'FH']\n",
    "col_labels = ['Lacunar/Subcortical', 'Small cortical', 'Big cortical/Main artery']\n",
    "graphs = ['DSC', 'VOL']\n",
    "\n",
    "for i in range(len(graphs)):\n",
    "    plt.close('all')\n",
    "    rows, cols = [4, 3]\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 12))\n",
    "\n",
    "    for ax, col in zip(axes[0], col_labels):\n",
    "        ax.set_title(col, pad=30, size=15)\n",
    "\n",
    "    for ax, row in zip(axes[:,0], row_labels):\n",
    "        ax.set_ylabel(row, rotation='vertical', size=15)\n",
    "        ax.yaxis.set_label_coords(-0.2, 0.5)\n",
    "\n",
    "\n",
    "    for j in range(1,rows+1):\n",
    "        for k in range(1,cols+1):\n",
    "            # Get reference metric\n",
    "            ref = np.array([x[i] for x in bland_altman_metrics['0'][str(k)]])\n",
    "            # Get subjects metric\n",
    "            metrics = np.array([x[i] for x in bland_altman_metrics[str(j)][str(k)]])\n",
    "            # COnver mm3 to cm3\n",
    "            if i == 1:\n",
    "                ref, metrics = [ref*0.001, metrics*0.001]\n",
    "            # Compute difference (Y) and average (X)\n",
    "            diff, avg = [ref - metrics, np.mean(np.array([ref, metrics]), axis=0)]\n",
    "            # Compute mean and std of differences\n",
    "            diff_mean, diff_std = [np.mean(diff), np.std(diff)]\n",
    "            # Plot difference against average\n",
    "            axes[j-1,k-1].plot(avg, diff, 'ro')\n",
    "            # Plot mean difference line and std lines\n",
    "            axes[j-1,k-1].axhline(diff_mean, color='k', label='Mean difference (%.2f)' % diff_mean)\n",
    "            axes[j-1,k-1].axhline(diff_mean + 1.9*diff_std, linestyle='--', color='k',\n",
    "                                  label='Mean' + r'$\\pm1.96$' + ' STD')\n",
    "            axes[j-1,k-1].axhline(diff_mean - 1.9*diff_std, linestyle='--', color='k')\n",
    "            \n",
    "            if i == 0:                \n",
    "                axes[j-1,k-1].set_xlim([0.5,1])\n",
    "                axes[j-1,k-1].set_ylim([0,1])\n",
    "            \n",
    "            if k == cols:\n",
    "                axes[j-1,k-1].set_ylabel('Difference (GT - Pred)\\n%s' % ('DSC (F1S)' if i == 0 else 'Volume (cm3)'), size=12)\n",
    "                axes[j-1,k-1].yaxis.set_label_coords(1.2, 0.5)\n",
    "            \n",
    "            if j == rows:\n",
    "                axes[j-1,k-1].set_xlabel('Average (Pred, GT)\\n%s' % ('DSC (F1S)' if i == 0 else 'Volume (cm3)'), size=12)\n",
    "            \n",
    "            axes[j-1,k-1].legend(loc='lower left')\n",
    "            \n",
    "            axes[j-1,k-1].grid()\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "    #plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    plt.savefig(os.path.join(root, model_name + '_bland_altman_%s.pdf' % graphs[i]), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METRICS SUMMARY TABLE**\n",
    "\n",
    "Table with as many rows as metrics. Columns: Base, THT V0, % Improvement, THT V1, % Improvement, Fill Holes, % Improvement. Use pandas for the table (dataframe) so that it can be exported to latex: pd.to_latex()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Load all test cases from all folds (43)\n",
    "summary_table_metrics = {'0':{'1':[], '2':[], '3':[]},\n",
    "                         '1':{'1':[], '2':[], '3':[]},\n",
    "                         '2':{'1':[], '2':[], '3':[]},\n",
    "                         '3':{'1':[], '2':[], '3':[]}}\n",
    "\n",
    "# Define keys\n",
    "keys = np.array(['F1S', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV'])\n",
    "x_labels = ['DSC', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        \n",
    "        subject, _, _, _, _, _, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "        stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "        # Store only the metrics that go from 0 to 1\n",
    "        summary_table_metrics['0'][stroke_type].append([metrics[key] for key in keys])        \n",
    "\n",
    "        metrics = all_test_metrics_tht_v0[os.path.basename(model)][i]\n",
    "        summary_table_metrics['1'][stroke_type].append([metrics[key] for key in keys])        \n",
    "        \n",
    "        metrics = all_test_metrics_tht_v1[os.path.basename(model)][i]\n",
    "        summary_table_metrics['2'][stroke_type].append([metrics[key] for key in keys])\n",
    "        \n",
    "        metrics = all_test_metrics_de[os.path.basename(model)][i]\n",
    "        summary_table_metrics['3'][stroke_type].append([metrics[key] for key in keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALl metrics\n",
    "data_base = np.array([np.nanmean(summary_table_metrics['0']['1'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['0']['1'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['0']['2'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['0']['2'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['0']['3'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['0']['3'], axis=0)])\n",
    "\n",
    "all_0 = np.array([np.nanmean(np.vstack((summary_table_metrics['0']['1'],\n",
    "                                     summary_table_metrics['0']['2'],\n",
    "                                     summary_table_metrics['0']['3'])), axis=0),\n",
    "                  np.nanstd(np.vstack((summary_table_metrics['0']['1'],\n",
    "                                    summary_table_metrics['0']['2'],\n",
    "                                    summary_table_metrics['0']['3'])), axis=0)])\n",
    "\n",
    "data_tht_v0 = np.array([np.nanmean(summary_table_metrics['1']['1'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['1']['1'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['1']['2'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['1']['2'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['1']['3'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['1']['3'], axis=0)])\n",
    "\n",
    "all_1 = np.array([np.nanmean(np.vstack((summary_table_metrics['1']['1'],\n",
    "                                     summary_table_metrics['1']['2'],\n",
    "                                     summary_table_metrics['1']['3'])), axis=0),\n",
    "                  np.nanstd(np.vstack((summary_table_metrics['1']['1'],\n",
    "                                    summary_table_metrics['1']['2'],\n",
    "                                    summary_table_metrics['1']['3'])), axis=0)])\n",
    "\n",
    "data_tht_v1 = np.array([np.nanmean(summary_table_metrics['2']['1'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['2']['1'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['2']['2'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['2']['2'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['2']['3'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['2']['3'], axis=0)])\n",
    "\n",
    "all_2 = np.array([np.nanmean(np.vstack((summary_table_metrics['2']['1'],\n",
    "                                     summary_table_metrics['2']['2'],\n",
    "                                     summary_table_metrics['2']['3'])), axis=0),\n",
    "                  np.nanstd(np.vstack((summary_table_metrics['2']['1'],\n",
    "                                    summary_table_metrics['2']['2'],\n",
    "                                    summary_table_metrics['2']['3'])), axis=0)])\n",
    "\n",
    "data_de = np.array([np.nanmean(summary_table_metrics['3']['1'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['3']['1'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['3']['2'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['3']['2'], axis=0),\n",
    "                      np.nanmean(summary_table_metrics['3']['3'], axis=0),\n",
    "                      np.nanstd(summary_table_metrics['3']['3'], axis=0)])\n",
    "\n",
    "all_3 = np.array([np.nanmean(np.vstack((summary_table_metrics['3']['1'],\n",
    "                                     summary_table_metrics['3']['2'],\n",
    "                                     summary_table_metrics['3']['3'])), axis=0),\n",
    "                  np.nanstd(np.vstack((summary_table_metrics['3']['1'],\n",
    "                                    summary_table_metrics['3']['2'],\n",
    "                                    summary_table_metrics['3']['3'])), axis=0)])\n",
    "\n",
    "data = np.concatenate((data_base, all_0,\n",
    "                       data_tht_v0, all_1,\n",
    "                       data_tht_v1, all_2,\n",
    "                       data_de, all_3)).T\n",
    "\n",
    "header = [np.array(['Base']*8 + ['THT0']*8 + \\\n",
    "                   ['THT1']*8 + ['FH']*8),\n",
    "          np.array(['L', 'L', 'S', 'S', 'B', 'B', 'ALL', 'ALL']*4),\n",
    "          np.array(['AVG', 'STD']*16)]\n",
    "\n",
    "df = pd.DataFrame(data, index=x_labels, columns=header)\n",
    "df = df.round(2)\n",
    "\n",
    "# Save dataframe in latex format\n",
    "out = open(os.path.join(root, model_name + '_metrics_table_0'), \"w\")\n",
    "print >> out, df.T.to_latex(column_format='|c|c|c|ccccccc|',\n",
    "                            longtable=True, bold_rows=True, multicolumn_format='c',\n",
    "                            multirow=True)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvement metrics\n",
    "data_improv_0 = np.vstack(((data_tht_v0[[0,2,4]] - data_base[[0,2,4]]) / data_base[[0,2,4]] * 100,\n",
    "                          (all_1[0] - all_0[0]) / all_0[0] * 100))\n",
    "data_improv_1 = np.vstack(((data_tht_v1[[0,2,4]] - data_base[[0,2,4]]) / data_base[[0,2,4]] * 100,\n",
    "                           (all_2[0] - all_0[0]) / all_0[0] * 100))\n",
    "data_improv_2 = np.vstack(((data_de[[0,2,4]] - data_base[[0,2,4]]) / data_base[[0,2,4]] * 100,\n",
    "                           (all_3[0] - all_0[0]) / all_0[0] * 100))\n",
    "\n",
    "data_improv = np.concatenate((data_improv_0,\n",
    "                              data_improv_1,\n",
    "                              data_improv_2))\n",
    "\n",
    "header = [np.array(['THT0']*4 + \\\n",
    "                   ['THT1']*4 + ['FH']*4),\n",
    "          np.array(['L', 'S', 'B', 'ALL']*3)]\n",
    "df = pd.DataFrame(data_improv.T, index=x_labels, columns=header)\n",
    "df = df.round(2)\n",
    "\n",
    "# Save dataframe in latex format\n",
    "out = open(os.path.join(root, model_name + '_metrics_table_1'), \"w\")\n",
    "print >> out, df.T.to_latex(column_format='|c|c|ccccccc|',\n",
    "                            longtable=True, bold_rows=True, multicolumn_format='c',\n",
    "                            multirow=True)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CORRELATION BETWEEN METRICS AND VOLUME**\n",
    "\n",
    "Coefficient of Correlation\n",
    "\n",
    "Value of r\tStrength of relationship\n",
    "\n",
    "-1.0 to -0.5 or 1.0 to 0.5\tStrong\n",
    "\n",
    "-0.5 to -0.3 or 0.3 to 0.5\tModerate\n",
    "\n",
    "-0.3 to -0.1 or 0.1 to 0.3\tWeak\n",
    "\n",
    "-0.1 to 0.1\tNone or very weak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all test cases from all folds (43)\n",
    "corr_metrics = {'0': [], '1': [], '2': [], '3': []}\n",
    "corr_volumes = []\n",
    "\n",
    "keys = np.array(['F1S', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV'])\n",
    "\n",
    "for model in trained_models:\n",
    "    # Load metrics from network\n",
    "    with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "        all_test_metrics = pickle.load(input)\n",
    "    # Load metrics from tht_v0\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v0 = pickle.load(input)\n",
    "    # Load metrics from tht_v1\n",
    "    with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "        all_test_metrics_tht_v1 = pickle.load(input)\n",
    "    # Load metrics from de\n",
    "    with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "        all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "    for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "        \n",
    "        subject, _, subject_label, pred_path, _, pmap_1_path, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "        \n",
    "        # 0 - Original label\n",
    "        corr_volumes.append(np.sum(nib.load(subject_label).get_data()))\n",
    "        \n",
    "        # 1 - Base\n",
    "        #vol = np.sum(nib.load(pred_path).get_data())\n",
    "        corr_metrics['0'].append([metrics[key] for key in keys])\n",
    "        \n",
    "        # 2 - THT v0\n",
    "        metrics = all_test_metrics_tht_v0[os.path.basename(model)][i]\n",
    "        th = all_test_metrics_tht_v0[os.path.basename(model)][i]['TH_OP']\n",
    "        #vol = np.sum(nib.load(pmap_1_path).get_data() > th)\n",
    "        corr_metrics['1'].append([metrics[key] for key in keys])\n",
    "        \n",
    "        # 3 - THT v1\n",
    "        metrics = all_test_metrics_tht_v1[os.path.basename(model)][i]\n",
    "        th = all_test_metrics_tht_v1[os.path.basename(model)][i]['TH_OP']\n",
    "        #vol = np.sum(nib.load(pmap_1_path).get_data() > th)\n",
    "        corr_metrics['2'].append([metrics[key] for key in keys])\n",
    "        \n",
    "        # 4 - Fill holes\n",
    "        metrics = all_test_metrics_de[os.path.basename(model)][i]\n",
    "        N_iter = all_test_metrics_de[os.path.basename(model)][i]['N_iter']\n",
    "        struct = ball(3)\n",
    "        #vol = np.sum(binary_closing(nib.load(pred_path).get_data(), struct, iterations=N_iter))\n",
    "        corr_metrics['3'].append([metrics[key] for key in keys])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each stage (base, tht v0,...) and each metric, compute correlation with volume\n",
    "col_labels = ['Base', 'THT0', 'THT1', 'FH']\n",
    "row_labels = ['DSC', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "plt.close('all')\n",
    "rows, cols = [len(row_labels), len(col_labels)]\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(4*cols, 2*rows))\n",
    "\n",
    "for ax, col in zip(axes[0], col_labels):\n",
    "    ax.set_title(col, pad=25, size=15)\n",
    "\n",
    "for ax, row in zip(axes[:,0], row_labels):\n",
    "    ax.set_ylabel(row, rotation='horizontal', size=15)\n",
    "    ax.yaxis.set_label_coords(-0.3, 0.5)\n",
    "    \n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        metric = np.array([x[i] for x in corr_metrics[str(j)]])\n",
    "        volumes = np.array(corr_volumes)*0.001\n",
    "        corr, p = pearsonr(metric, volumes)\n",
    "        \n",
    "        idx = np.lexsort((metric, volumes))\n",
    "        \n",
    "        axes[i,j].scatter(volumes[idx], metric[idx], c='r')\n",
    "                \n",
    "        axes[i,j].set_xlim([0,25])    \n",
    "        \n",
    "        if i != 1:\n",
    "            axes[i,j].set_ylim([0,1])\n",
    "        else:\n",
    "            axes[i,j].set_ylim([0,150])\n",
    "        \n",
    "        if i == rows-1:\n",
    "            axes[i,j].set_xlabel('r=%0.2f, p=%0.5f' % (corr, p) + '\\n\\nGT volume (cm3)', size = 15)\n",
    "        else:\n",
    "            axes[i,j].set_xlabel('r=%0.2f, p=%0.5f' % (corr, p), size = 15)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.2)\n",
    "fig.savefig(os.path.join(root, model_name + '_corr_figure.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V0 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V0_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V0_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V0_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V0_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V0_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V0_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V0_de = pickle.load(input)\n",
    "\n",
    "# V1 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V1_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V1_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V1_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V1_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V1_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V1_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V1_de = pickle.load(input)\n",
    "\n",
    "# V2 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V2_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V2 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V2_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V2_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V2_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V2_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V2_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V2_de = pickle.load(input)\n",
    "    \n",
    "# V3 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V3_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V3 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V3_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V3_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V3_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V3_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V3_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V3_de = pickle.load(input)\n",
    "    \n",
    "# V4 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V4_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V4 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V4_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V4_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V4_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V4_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V4_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V4_de = pickle.load(input)\n",
    "    \n",
    "# V5 files\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V5_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V5 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V5_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V5_tht_v0 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V5_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V5_tht_v1 = pickle.load(input)\n",
    "with open('/media/uziel/Pulga2/DISS/milestones_6/V5_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V5_de = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V0_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V0_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V0_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V0_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V0_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V0_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V0_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V0_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V0_R_de = pickle.load(input)\n",
    "    \n",
    "# V1_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V1_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V1_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V1_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V1_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V1_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V1_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V1_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V1_R_de = pickle.load(input)\n",
    "    \n",
    "# V2_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V2_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V2_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V2_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V2_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V2_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V2_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V2_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V2_R_de = pickle.load(input)\n",
    "    \n",
    "# V3_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V3_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V3_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V3_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V3_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V3_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V3_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V3_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V3_R_de = pickle.load(input)\n",
    "    \n",
    "# V4_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V4_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V4_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V4_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V4_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V4_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V4_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V4_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V4_R_de = pickle.load(input)\n",
    "    \n",
    "# V5_R files\n",
    "with open('/home/uziel/DISS/milestones_6/V5_R_test_metrics.pkl', 'rb') as input:\n",
    "    test_metrics_V5_R = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V5_R_test_metrics_tht_v0.pkl', 'rb') as input:\n",
    "    test_metrics_V5_R_tht_v0 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V5_R_test_metrics_tht_v1.pkl', 'rb') as input:\n",
    "    test_metrics_V5_R_tht_v1 = pickle.load(input)\n",
    "with open('/home/uziel/DISS/milestones_6/V5_R_test_metrics_de.pkl', 'rb') as input:\n",
    "    test_metrics_V5_R_de = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUMMARY OF ALL EXPERIMENTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variants = ['DM_V0_[0-4]', 'DM_V1_[0-4]', 'DM_V2_[0-4]', 'DM_V3_[0-4]']\n",
    "\n",
    "# Load subjects per stroke subtypes\n",
    "stroke_types ={'1': ['training_6', 'training_9', 'training_10', 'training_11', 'training_12',\n",
    "                     'training_19', 'training_35', 'training_39', 'training_40', 'training_42'],\n",
    "               '2': ['training_1', 'training_2', 'training_15', 'training_21', 'training_28',\n",
    "                     'training_37', 'training_41'],\n",
    "               '3': ['training_4', 'training_5', 'training_7', 'training_8', 'training_13',\n",
    "                     'training_14', 'training_16', 'training_18', 'training_20', 'training_22',\n",
    "                     'training_23', 'training_24', 'training_26', 'training_27', 'training_30',\n",
    "                     'training_31', 'training_32', 'training_33', 'training_36', 'training_38',\n",
    "                     'training_43', 'training_44', 'training_45', 'training_46', 'training_47',\n",
    "                     'training_48']}\n",
    "\n",
    "# Load all test cases from all folds (43)\n",
    "summary_table_metrics = {'V0':\n",
    "                         {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '3':{'1':[], '2':[], '3':[], '4':[]}},\n",
    "                         'V1':\n",
    "                         {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '3':{'1':[], '2':[], '3':[], '4':[]}},\n",
    "                         'V2':\n",
    "                         {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '3':{'1':[], '2':[], '3':[], '4':[]}},\n",
    "                         'V3':\n",
    "                         {'0':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '1':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '2':{'1':[], '2':[], '3':[], '4':[]},\n",
    "                          '3':{'1':[], '2':[], '3':[], '4':[]}}}\n",
    "\n",
    "# Define keys\n",
    "keys = np.array(['F1S', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV'])\n",
    "x_labels = ['DSC', 'HD', 'JI', 'MCC', 'TPR', 'TNR', 'PPV']\n",
    "\n",
    "# Get all metrics from all experiments\n",
    "for model_variant in model_variants:\n",
    "    tmp = model_variant.split('_')\n",
    "    if len(tmp) == 3:\n",
    "        model_name = tmp[1]\n",
    "    elif len(tmp) == 4:\n",
    "        model_name = tmp[1] + '_' + tmp[2]\n",
    "    else:\n",
    "        model_name = tmp[1] + '_' + tmp[2] + '_' + tmp[3]\n",
    "\n",
    "    # Load all trained models (k-folds) of model_variant\n",
    "    trained_models = sorted(glob(os.path.join(root, model_variant)))\n",
    "\n",
    "    for model in trained_models:\n",
    "        # Load metrics from network\n",
    "        with open(os.path.join(root, model_name +  '_test_results.pkl'), 'rb') as input:\n",
    "            all_test_metrics = pickle.load(input)\n",
    "        # Load metrics from tht_v0\n",
    "        with open(os.path.join(root, model_name +  '_test_results_tht_v0.pkl'), 'rb') as input:\n",
    "            all_test_metrics_tht_v0 = pickle.load(input)\n",
    "        # Load metrics from tht_v1\n",
    "        with open(os.path.join(root, model_name +  '_test_results_tht_v1.pkl'), 'rb') as input:\n",
    "            all_test_metrics_tht_v1 = pickle.load(input)\n",
    "        # Load metrics from de\n",
    "        with open(os.path.join(root, model_name +  '_all_test_metrics_de.pkl'), 'rb') as input:\n",
    "            all_test_metrics_de = pickle.load(input)\n",
    "\n",
    "        for i in range(len(all_test_metrics[os.path.basename(model)])):\n",
    "\n",
    "            subject, _, _, _, _, _, _, metrics = all_test_metrics[os.path.basename(model)][i]\n",
    "            stroke_type = [key for key in stroke_types.keys() if subject in stroke_types[key]][0]\n",
    "            # Store only the metrics that go from 0 to 1\n",
    "            summary_table_metrics[model_name]['0'][stroke_type].append([metrics[key] for key in keys])\n",
    "            summary_table_metrics[model_name]['0']['4'].append([metrics[key] for key in keys])\n",
    "\n",
    "            metrics = all_test_metrics_tht_v0[os.path.basename(model)][i]\n",
    "            summary_table_metrics[model_name]['1'][stroke_type].append([metrics[key] for key in keys])\n",
    "            summary_table_metrics[model_name]['1']['4'].append([metrics[key] for key in keys])\n",
    "\n",
    "            metrics = all_test_metrics_tht_v1[os.path.basename(model)][i]\n",
    "            summary_table_metrics[model_name]['2'][stroke_type].append([metrics[key] for key in keys])\n",
    "            summary_table_metrics[model_name]['2']['4'].append([metrics[key] for key in keys])\n",
    "\n",
    "            metrics = all_test_metrics_de[os.path.basename(model)][i]\n",
    "            summary_table_metrics[model_name]['3'][stroke_type].append([metrics[key] for key in keys])\n",
    "            summary_table_metrics[model_name]['3']['4'].append([metrics[key] for key in keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUMMARY TABLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0_metrics = np.array([np.nanmean(np.vstack((summary_table_metrics['V0']['0']['1'],\n",
    "                                             summary_table_metrics['V0']['0']['2'],\n",
    "                                             summary_table_metrics['V0']['0']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V0']['1']['1'],\n",
    "                                             summary_table_metrics['V0']['1']['2'],\n",
    "                                             summary_table_metrics['V0']['1']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V0']['2']['1'],\n",
    "                                             summary_table_metrics['V0']['2']['2'],\n",
    "                                             summary_table_metrics['V0']['2']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V0']['3']['1'],\n",
    "                                             summary_table_metrics['V0']['3']['2'],\n",
    "                                             summary_table_metrics['V0']['3']['3'])),\n",
    "                                  axis=0)\n",
    "                      ])\n",
    "\n",
    "v1_metrics = np.array([np.nanmean(np.vstack((summary_table_metrics['V1']['0']['1'],\n",
    "                                             summary_table_metrics['V1']['0']['2'],\n",
    "                                             summary_table_metrics['V1']['0']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V1']['1']['1'],\n",
    "                                             summary_table_metrics['V1']['1']['2'],\n",
    "                                             summary_table_metrics['V1']['1']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V1']['2']['1'],\n",
    "                                             summary_table_metrics['V1']['2']['2'],\n",
    "                                             summary_table_metrics['V1']['2']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V1']['3']['1'],\n",
    "                                             summary_table_metrics['V1']['3']['2'],\n",
    "                                             summary_table_metrics['V1']['3']['3'])),\n",
    "                                  axis=0)\n",
    "                      ])\n",
    "\n",
    "v2_metrics = np.array([np.nanmean(np.vstack((summary_table_metrics['V2']['0']['1'],\n",
    "                                             summary_table_metrics['V2']['0']['2'],\n",
    "                                             summary_table_metrics['V2']['0']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V2']['1']['1'],\n",
    "                                             summary_table_metrics['V2']['1']['2'],\n",
    "                                             summary_table_metrics['V2']['1']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V2']['2']['1'],\n",
    "                                             summary_table_metrics['V2']['2']['2'],\n",
    "                                             summary_table_metrics['V2']['2']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V2']['3']['1'],\n",
    "                                             summary_table_metrics['V2']['3']['2'],\n",
    "                                             summary_table_metrics['V2']['3']['3'])),\n",
    "                                  axis=0)\n",
    "                      ])\n",
    "\n",
    "v3_metrics = np.array([np.nanmean(np.vstack((summary_table_metrics['V3']['0']['1'],\n",
    "                                             summary_table_metrics['V3']['0']['2'],\n",
    "                                             summary_table_metrics['V3']['0']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V3']['1']['1'],\n",
    "                                             summary_table_metrics['V3']['1']['2'],\n",
    "                                             summary_table_metrics['V3']['1']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V3']['2']['1'],\n",
    "                                             summary_table_metrics['V3']['2']['2'],\n",
    "                                             summary_table_metrics['V3']['2']['3'])),\n",
    "                                  axis=0),\n",
    "                       np.nanmean(np.vstack((summary_table_metrics['V3']['3']['1'],\n",
    "                                             summary_table_metrics['V3']['3']['2'],\n",
    "                                             summary_table_metrics['V3']['3']['3'])),\n",
    "                                  axis=0)\n",
    "                      ])\n",
    "\n",
    "data = np.concatenate((v0_metrics,\n",
    "                       v1_metrics,\n",
    "                       v2_metrics,\n",
    "                       v3_metrics)).T\n",
    "\n",
    "header =[np.array(['V0']*4 + ['V1']*4 + ['V2']*4 + ['V3']*4),\n",
    "         np.array(['Base', 'THT0', 'THT1', 'FH']*4)]\n",
    "\n",
    "df = pd.DataFrame(data, index=x_labels, columns=header)\n",
    "df = df.round(2)\n",
    "\n",
    "# Save dataframe in latex format\n",
    "out = open(os.path.join(root, 'summary_table'), \"w\")\n",
    "print >> out, df.T.to_latex(column_format='|c|c|c|cccccc|',\n",
    "                            longtable=True, bold_rows=True, multicolumn_format='c',\n",
    "                            multirow=True)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUMMARY ERROR BARS FIGURE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_labels = ['Base', 'THT0', 'THT1', 'FH']\n",
    "col_labels = ['Lacunar/\\nSubcortical', 'Small cortical', 'Big cortical/\\nMain artery', 'All']\n",
    "\n",
    "x_labels = ['V0', 'V1', 'V2', 'V3']\n",
    "\n",
    "plt.close('all')\n",
    "rows, cols = [4, 4]\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(2*cols, 2*rows))\n",
    "\n",
    "for ax, col in zip(axes[0], col_labels):\n",
    "    ax.set_title(col, pad=20, size=12)\n",
    "\n",
    "for ax, row in zip(axes[:,0], row_labels):\n",
    "    ax.set_ylabel(row, rotation='vertical', size=12)\n",
    "    ax.yaxis.set_label_coords(-0.5, 0.5)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(1,cols+1):\n",
    "        # Compute mean and confidence interval\n",
    "        metrics = np.array([[x[0] for x in summary_table_metrics['V0'][str(i)][str(j)]],\n",
    "                            [x[0] for x in summary_table_metrics['V1'][str(i)][str(j)]],\n",
    "                            [x[0] for x in summary_table_metrics['V2'][str(i)][str(j)]],\n",
    "                            [x[0] for x in summary_table_metrics['V3'][str(i)][str(j)]]]).T\n",
    "        \n",
    "        mean = np.mean(metrics, axis=0)\n",
    "        confidence_interval = st.t.interval(0.95, len(metrics[0])-1,\n",
    "                                            loc=mean, scale=st.sem(metrics, axis=0))\n",
    "        differences = (abs(confidence_interval[0] - mean), abs(confidence_interval[1] - mean))\n",
    "        \n",
    "        # Plot error bar\n",
    "        axes[i,j-1].grid()\n",
    "        axes[i,j-1].set_ylim([0,1])\n",
    "        axes[i,j-1].tick_params(axis='x', width=10)\n",
    "        (_, caps, _) = axes[i,j-1].errorbar(x_labels, mean, differences,\n",
    "                                    color='red', mew=5,\n",
    "                                    fmt='o', markersize=3, capsize=6)\n",
    "\n",
    "        for cap in caps:\n",
    "            cap.set_markeredgewidth(1)\n",
    "            \n",
    "        if j == cols:\n",
    "            axes[i,j-1].set_ylabel('DSC', size=12)\n",
    "            axes[i,j-1].yaxis.set_label_coords(1.3, 0.5)\n",
    "\n",
    "        if i == rows-1:\n",
    "            axes[i,j-1].set_xlabel('Experiments', size=12)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.5)\n",
    "plt.savefig(os.path.join(root, 'summary_error_bars.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
